{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale, scale, MinMaxScaler\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan.simulation import create_continuous_data\n",
    "from wgan.imblearn import GANbalancer\n",
    "import wgan.data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC\n",
    "from types import MethodType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import safe_indexing\n",
    "\n",
    "def create_samples(self, X, y):\n",
    "        # FIXME: uncomment in version 0.6\n",
    "        # self._validate_estimator()\n",
    "\n",
    "        for class_sample, n_samples in self.sampling_strategy_.items():\n",
    "            if n_samples == 0:\n",
    "                continue\n",
    "            target_class_indices = np.flatnonzero(y == class_sample)\n",
    "            X_class = safe_indexing(X, target_class_indices)\n",
    "\n",
    "            self.nn_k_.fit(X_class)\n",
    "            nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]\n",
    "            X_new, y_new = self._make_samples(X_class, y.dtype, class_sample,\n",
    "                                              X_class, nns, n_samples, 1.0)\n",
    "\n",
    "        return X_new, y_new\n",
    "\n",
    "\n",
    "SMOTE._sample_only = create_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifical Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 5000\n",
    "N_VAR = 6\n",
    "data = {\n",
    "    \"Independent\" : create_continuous_data(n_samples=N_SAMPLES, n_var=N_VAR, n_dependent=0, pos_ratio=0),\n",
    "    \"Dependent\" : create_continuous_data(n_samples=N_SAMPLES, n_var=N_VAR, n_dependent=5, pos_ratio=0),\n",
    "    \"Mixed\" : create_continuous_data(n_samples=N_SAMPLES, n_var=N_VAR, n_dependent=N_VAR//2, pos_ratio=0)\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_balancer = GANbalancer(idx_cont=range(N_VAR), categorical=None, auxiliary=False,\n",
    "                           generator_input=N_VAR*1, generator_layers=None, \n",
    "                           critic_layers=[N_VAR, N_VAR], critic_iterations=5,\n",
    "                           learning_rate = [5e-5, 5e-5],\n",
    "                           batch_size = 128, n_iter=2500, \n",
    "                           sampling_strategy = {0:N_SAMPLES, 1:0}, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy = {0:N_SAMPLES, 1:0})\n",
    "smote._validate_estimator()\n",
    "smote.sampling_strategy_ = {0:N_SAMPLES, 1:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_first_moments(X):\n",
    "    return np.vstack([x.mean(axis=0) for x in X])\n",
    "\n",
    "def check_second_moments(X):\n",
    "    return [np.cov(x, rowvar=False).round(2) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Normal RVs - First and Second Moment Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/2500 [00:00<08:03,  5.17it/s]\u001b[A\n",
      "  0%|          | 3/2500 [00:00<06:43,  6.20it/s]\u001b[A\n",
      "  0%|          | 4/2500 [00:00<07:00,  5.94it/s]\u001b[A\n",
      "  0%|          | 6/2500 [00:00<05:57,  6.97it/s]\u001b[A\n",
      "  0%|          | 8/2500 [00:00<05:14,  7.93it/s]\u001b[A\n",
      "  0%|          | 9/2500 [00:01<05:58,  6.96it/s]\u001b[A\n",
      "  1%|          | 16/2500 [00:01<04:29,  9.21it/s]\u001b[A\n",
      "  1%|          | 24/2500 [00:01<03:25, 12.07it/s]\u001b[A\n",
      "  1%|▏         | 32/2500 [00:01<02:44, 15.04it/s]\u001b[A\n",
      "  2%|▏         | 40/2500 [00:01<02:12, 18.57it/s]\u001b[A\n",
      "  2%|▏         | 48/2500 [00:02<01:50, 22.24it/s]\u001b[A\n",
      "  2%|▏         | 56/2500 [00:02<01:36, 25.35it/s]\u001b[A\n",
      "  3%|▎         | 64/2500 [00:02<01:24, 28.71it/s]\u001b[A\n",
      "  3%|▎         | 72/2500 [00:02<01:20, 30.28it/s]\u001b[A\n",
      "  3%|▎         | 80/2500 [00:02<01:12, 33.35it/s]\u001b[A\n",
      "  4%|▎         | 88/2500 [00:03<01:06, 36.41it/s]\u001b[A\n",
      "  4%|▍         | 96/2500 [00:03<01:03, 38.00it/s]\u001b[A\n",
      "  4%|▍         | 104/2500 [00:03<01:05, 36.35it/s]\u001b[A\n",
      "  4%|▍         | 112/2500 [00:03<01:01, 38.88it/s]\u001b[A\n",
      "  5%|▍         | 120/2500 [00:03<00:59, 39.93it/s]\u001b[A\n",
      "  5%|▌         | 128/2500 [00:04<00:58, 40.31it/s]\u001b[A\n",
      "  5%|▍         | 1184/25000 [00:40<09:35, 41.39it/s]\n",
      "  6%|▌         | 144/2500 [00:04<00:59, 39.40it/s]\u001b[A\n",
      "  6%|▌         | 152/2500 [00:04<00:59, 39.20it/s]\u001b[A\n",
      "  6%|▋         | 160/2500 [00:04<01:01, 37.88it/s]\u001b[A\n",
      "  7%|▋         | 168/2500 [00:05<00:58, 39.83it/s]\u001b[A\n",
      "  7%|▋         | 176/2500 [00:05<00:56, 40.99it/s]\u001b[A\n",
      "  7%|▋         | 184/2500 [00:05<00:55, 41.70it/s]\u001b[A\n",
      "  8%|▊         | 192/2500 [00:05<00:53, 42.74it/s]\u001b[A\n",
      "  8%|▊         | 200/2500 [00:05<00:52, 43.81it/s]\u001b[A\n",
      "  8%|▊         | 208/2500 [00:05<00:51, 44.45it/s]\u001b[A\n",
      "  9%|▊         | 216/2500 [00:06<00:51, 44.19it/s]\u001b[A\n",
      "  9%|▉         | 224/2500 [00:06<00:55, 40.82it/s]\u001b[A\n",
      "  9%|▉         | 232/2500 [00:06<00:56, 39.97it/s]\u001b[A\n",
      " 10%|▉         | 240/2500 [00:06<00:54, 41.63it/s]\u001b[A\n",
      " 10%|▉         | 248/2500 [00:06<00:52, 43.18it/s]\u001b[A\n",
      " 10%|█         | 256/2500 [00:07<00:53, 42.02it/s]\u001b[A\n",
      " 11%|█         | 264/2500 [00:07<00:51, 43.31it/s]\u001b[A\n",
      " 11%|█         | 272/2500 [00:07<00:52, 42.82it/s]\u001b[A\n",
      " 11%|█         | 280/2500 [00:07<00:50, 44.07it/s]\u001b[A\n",
      " 12%|█▏        | 288/2500 [00:07<00:53, 41.02it/s]\u001b[A\n",
      " 12%|█▏        | 296/2500 [00:08<00:53, 41.27it/s]\u001b[A\n",
      " 12%|█▏        | 304/2500 [00:08<00:51, 42.67it/s]\u001b[A\n",
      " 12%|█▏        | 312/2500 [00:08<00:51, 42.83it/s]\u001b[A\n",
      " 13%|█▎        | 320/2500 [00:08<00:52, 41.92it/s]\u001b[A\n",
      " 13%|█▎        | 328/2500 [00:08<00:50, 43.22it/s]\u001b[A\n",
      " 13%|█▎        | 336/2500 [00:08<00:48, 44.27it/s]\u001b[A\n",
      " 14%|█▍        | 344/2500 [00:09<00:52, 41.31it/s]\u001b[A\n",
      " 14%|█▍        | 352/2500 [00:09<00:51, 42.04it/s]\u001b[A\n",
      " 14%|█▍        | 360/2500 [00:09<00:53, 40.13it/s]\u001b[A\n",
      " 15%|█▍        | 368/2500 [00:09<00:52, 40.94it/s]\u001b[A\n",
      " 15%|█▌        | 376/2500 [00:09<00:51, 41.08it/s]\u001b[A\n",
      " 15%|█▌        | 384/2500 [00:10<00:49, 42.35it/s]\u001b[A\n",
      " 16%|█▌        | 392/2500 [00:10<00:48, 43.47it/s]\u001b[A\n",
      " 16%|█▌        | 400/2500 [00:10<00:52, 40.31it/s]\u001b[A\n",
      " 16%|█▋        | 408/2500 [00:10<00:49, 42.24it/s]\u001b[A\n",
      " 17%|█▋        | 416/2500 [00:10<00:52, 40.00it/s]\u001b[A\n",
      " 17%|█▋        | 424/2500 [00:11<00:53, 38.79it/s]\u001b[A\n",
      " 17%|█▋        | 432/2500 [00:11<00:52, 39.47it/s]\u001b[A\n",
      " 18%|█▊        | 440/2500 [00:11<00:55, 37.02it/s]\u001b[A\n",
      " 18%|█▊        | 448/2500 [00:11<00:53, 38.60it/s]\u001b[A\n",
      " 18%|█▊        | 456/2500 [00:11<00:50, 40.17it/s]\u001b[A\n",
      " 19%|█▊        | 464/2500 [00:12<00:52, 38.78it/s]\u001b[A\n",
      " 19%|█▉        | 472/2500 [00:12<00:58, 34.75it/s]\u001b[A\n",
      " 19%|█▉        | 480/2500 [00:12<00:54, 37.10it/s]\u001b[A\n",
      " 20%|█▉        | 488/2500 [00:12<00:50, 39.67it/s]\u001b[A\n",
      " 20%|█▉        | 496/2500 [00:13<00:48, 41.07it/s]\u001b[A\n",
      " 20%|██        | 504/2500 [00:13<00:50, 39.46it/s]\u001b[A\n",
      " 20%|██        | 512/2500 [00:13<00:50, 39.66it/s]\u001b[A\n",
      " 21%|██        | 520/2500 [00:13<00:48, 40.89it/s]\u001b[A\n",
      " 21%|██        | 528/2500 [00:13<00:47, 41.87it/s]\u001b[A\n",
      " 21%|██▏       | 536/2500 [00:13<00:47, 41.70it/s]\u001b[A\n",
      " 22%|██▏       | 544/2500 [00:14<00:47, 40.83it/s]\u001b[A\n",
      " 22%|██▏       | 552/2500 [00:14<00:46, 41.69it/s]\u001b[A\n",
      " 22%|██▏       | 560/2500 [00:14<00:45, 42.43it/s]\u001b[A\n",
      " 23%|██▎       | 568/2500 [00:14<00:45, 42.92it/s]\u001b[A\n",
      " 23%|██▎       | 576/2500 [00:14<00:45, 42.63it/s]\u001b[A\n",
      " 23%|██▎       | 584/2500 [00:15<00:44, 42.69it/s]\u001b[A\n",
      " 24%|██▎       | 592/2500 [00:15<00:43, 43.68it/s]\u001b[A\n",
      " 24%|██▍       | 600/2500 [00:15<00:43, 43.51it/s]\u001b[A\n",
      " 24%|██▍       | 608/2500 [00:15<00:43, 43.94it/s]\u001b[A\n",
      " 25%|██▍       | 616/2500 [00:15<00:42, 44.12it/s]\u001b[A\n",
      " 25%|██▍       | 624/2500 [00:16<00:42, 44.38it/s]\u001b[A\n",
      " 25%|██▌       | 632/2500 [00:16<00:44, 41.89it/s]\u001b[A\n",
      " 26%|██▌       | 640/2500 [00:16<00:47, 39.19it/s]\u001b[A\n",
      " 26%|██▌       | 648/2500 [00:16<00:49, 37.75it/s]\u001b[A\n",
      " 26%|██▌       | 656/2500 [00:16<00:48, 37.65it/s]\u001b[A\n",
      " 27%|██▋       | 664/2500 [00:17<00:46, 39.15it/s]\u001b[A\n",
      " 27%|██▋       | 672/2500 [00:17<00:44, 40.67it/s]\u001b[A\n",
      " 27%|██▋       | 680/2500 [00:17<00:44, 40.83it/s]\u001b[A\n",
      " 28%|██▊       | 688/2500 [00:17<00:43, 41.50it/s]\u001b[A\n",
      " 28%|██▊       | 696/2500 [00:17<00:42, 42.68it/s]\u001b[A\n",
      " 28%|██▊       | 704/2500 [00:18<00:42, 42.23it/s]\u001b[A\n",
      " 28%|██▊       | 712/2500 [00:18<00:45, 38.98it/s]\u001b[A\n",
      " 29%|██▉       | 720/2500 [00:18<00:43, 40.87it/s]\u001b[A\n",
      " 29%|██▉       | 728/2500 [00:18<00:43, 40.89it/s]\u001b[A\n",
      " 29%|██▉       | 736/2500 [00:18<00:42, 41.82it/s]\u001b[A\n",
      " 30%|██▉       | 744/2500 [00:18<00:40, 42.89it/s]\u001b[A\n",
      " 30%|███       | 752/2500 [00:19<00:40, 42.89it/s]\u001b[A\n",
      " 30%|███       | 760/2500 [00:19<00:40, 42.75it/s]\u001b[A\n",
      " 31%|███       | 768/2500 [00:19<00:39, 43.72it/s]\u001b[A\n",
      " 31%|███       | 776/2500 [00:19<00:38, 44.63it/s]\u001b[A\n",
      " 31%|███▏      | 784/2500 [00:19<00:38, 44.82it/s]\u001b[A\n",
      " 32%|███▏      | 792/2500 [00:20<00:42, 40.42it/s]\u001b[A\n",
      " 32%|███▏      | 800/2500 [00:20<00:41, 41.13it/s]\u001b[A\n",
      " 32%|███▏      | 808/2500 [00:20<00:40, 41.30it/s]\u001b[A\n",
      " 33%|███▎      | 816/2500 [00:20<00:39, 42.63it/s]\u001b[A\n",
      " 33%|███▎      | 824/2500 [00:20<00:38, 43.25it/s]\u001b[A\n",
      " 33%|███▎      | 832/2500 [00:21<00:38, 43.62it/s]\u001b[A\n",
      " 34%|███▎      | 840/2500 [00:21<00:38, 43.52it/s]\u001b[A\n",
      " 34%|███▍      | 848/2500 [00:21<00:39, 42.33it/s]\u001b[A\n",
      " 34%|███▍      | 856/2500 [00:21<00:42, 38.92it/s]\u001b[A\n",
      " 35%|███▍      | 864/2500 [00:21<00:41, 39.78it/s]\u001b[A\n",
      " 35%|███▍      | 872/2500 [00:22<00:39, 41.08it/s]\u001b[A\n",
      " 35%|███▌      | 880/2500 [00:22<00:38, 41.83it/s]\u001b[A\n",
      " 36%|███▌      | 888/2500 [00:22<00:38, 42.30it/s]\u001b[A\n",
      " 36%|███▌      | 896/2500 [00:22<00:38, 41.74it/s]\u001b[A\n",
      " 36%|███▌      | 904/2500 [00:22<00:37, 42.68it/s]\u001b[A\n",
      " 36%|███▋      | 912/2500 [00:22<00:36, 43.11it/s]\u001b[A\n",
      " 37%|███▋      | 920/2500 [00:23<00:39, 39.97it/s]\u001b[A\n",
      " 37%|███▋      | 928/2500 [00:23<00:40, 39.01it/s]\u001b[A\n",
      " 37%|███▋      | 936/2500 [00:23<00:43, 36.14it/s]\u001b[A\n",
      " 38%|███▊      | 944/2500 [00:23<00:43, 35.72it/s]\u001b[A\n",
      " 38%|███▊      | 952/2500 [00:24<00:41, 37.11it/s]\u001b[A\n",
      " 38%|███▊      | 960/2500 [00:24<00:39, 38.85it/s]\u001b[A\n",
      " 39%|███▊      | 968/2500 [00:24<00:41, 37.27it/s]\u001b[A\n",
      " 39%|███▉      | 976/2500 [00:24<00:38, 39.58it/s]\u001b[A\n",
      " 39%|███▉      | 984/2500 [00:24<00:36, 41.56it/s]\u001b[A\n",
      " 40%|███▉      | 992/2500 [00:25<00:35, 42.19it/s]\u001b[A\n",
      " 40%|████      | 1000/2500 [00:25<00:35, 42.57it/s]\u001b[A\n",
      " 40%|████      | 1008/2500 [00:25<00:35, 42.33it/s]\u001b[A\n",
      " 41%|████      | 1016/2500 [00:25<00:34, 42.57it/s]\u001b[A\n",
      " 41%|████      | 1024/2500 [00:25<00:33, 43.58it/s]\u001b[A\n",
      " 41%|████▏     | 1032/2500 [00:25<00:33, 43.87it/s]\u001b[A\n",
      " 42%|████▏     | 1040/2500 [00:26<00:33, 43.59it/s]\u001b[A\n",
      " 42%|████▏     | 1048/2500 [00:26<00:32, 44.19it/s]\u001b[A\n",
      " 42%|████▏     | 1056/2500 [00:26<00:33, 42.70it/s]\u001b[A\n",
      " 43%|████▎     | 1064/2500 [00:26<00:34, 41.39it/s]\u001b[A\n",
      " 43%|████▎     | 1072/2500 [00:26<00:38, 37.46it/s]\u001b[A\n",
      " 43%|████▎     | 1080/2500 [00:27<00:37, 38.04it/s]\u001b[A\n",
      " 44%|████▎     | 1088/2500 [00:27<00:36, 39.00it/s]\u001b[A\n",
      " 44%|████▍     | 1096/2500 [00:27<00:34, 40.56it/s]\u001b[A\n",
      " 44%|████▍     | 1104/2500 [00:27<00:33, 41.51it/s]\u001b[A\n",
      " 44%|████▍     | 1112/2500 [00:27<00:34, 40.78it/s]\u001b[A\n",
      " 45%|████▍     | 1120/2500 [00:28<00:33, 40.92it/s]\u001b[A\n",
      " 45%|████▌     | 1128/2500 [00:28<00:32, 41.86it/s]\u001b[A\n",
      " 45%|████▌     | 1136/2500 [00:28<00:33, 41.29it/s]\u001b[A\n",
      " 46%|████▌     | 1144/2500 [00:28<00:32, 42.07it/s]\u001b[A\n",
      " 46%|████▌     | 1152/2500 [00:28<00:31, 42.63it/s]\u001b[A\n",
      " 46%|████▋     | 1160/2500 [00:29<00:32, 41.79it/s]\u001b[A\n",
      " 47%|████▋     | 1168/2500 [00:29<00:32, 41.61it/s]\u001b[A\n",
      " 47%|████▋     | 1176/2500 [00:29<00:31, 42.04it/s]\u001b[A\n",
      " 47%|████▋     | 1184/2500 [00:29<00:30, 42.74it/s]\u001b[A\n",
      " 48%|████▊     | 1192/2500 [00:29<00:30, 43.16it/s]\u001b[A\n",
      " 48%|████▊     | 1200/2500 [00:30<00:30, 43.23it/s]\u001b[A\n",
      " 48%|████▊     | 1208/2500 [00:30<00:29, 43.35it/s]\u001b[A\n",
      " 49%|████▊     | 1216/2500 [00:30<00:29, 42.90it/s]\u001b[A\n",
      " 49%|████▉     | 1224/2500 [00:30<00:30, 42.45it/s]\u001b[A\n",
      " 49%|████▉     | 1232/2500 [00:30<00:29, 42.69it/s]\u001b[A\n",
      " 50%|████▉     | 1240/2500 [00:30<00:30, 40.97it/s]\u001b[A\n",
      " 50%|████▉     | 1248/2500 [00:31<00:30, 41.17it/s]\u001b[A\n",
      " 50%|█████     | 1256/2500 [00:31<00:30, 40.43it/s]\u001b[A\n",
      " 51%|█████     | 1264/2500 [00:31<00:29, 41.29it/s]\u001b[A\n",
      " 51%|█████     | 1272/2500 [00:31<00:29, 42.27it/s]\u001b[A\n",
      " 51%|█████     | 1280/2500 [00:31<00:28, 42.53it/s]\u001b[A\n",
      " 52%|█████▏    | 1288/2500 [00:32<00:28, 42.84it/s]\u001b[A\n",
      " 52%|█████▏    | 1296/2500 [00:32<00:28, 42.73it/s]\u001b[A\n",
      " 52%|█████▏    | 1304/2500 [00:32<00:28, 41.58it/s]\u001b[A\n",
      " 52%|█████▏    | 1312/2500 [00:32<00:27, 42.61it/s]\u001b[A\n",
      " 53%|█████▎    | 1320/2500 [00:32<00:27, 42.93it/s]\u001b[A\n",
      " 53%|█████▎    | 1328/2500 [00:33<00:27, 42.99it/s]\u001b[A\n",
      " 53%|█████▎    | 1336/2500 [00:33<00:29, 39.95it/s]\u001b[A\n",
      " 54%|█████▍    | 1344/2500 [00:33<00:29, 39.61it/s]\u001b[A\n",
      " 54%|█████▍    | 1352/2500 [00:33<00:28, 40.44it/s]\u001b[A\n",
      " 54%|█████▍    | 1360/2500 [00:33<00:27, 40.76it/s]\u001b[A\n",
      " 55%|█████▍    | 1368/2500 [00:34<00:28, 40.32it/s]\u001b[A\n",
      " 55%|█████▌    | 1376/2500 [00:34<00:27, 40.96it/s]\u001b[A\n",
      " 55%|█████▌    | 1384/2500 [00:34<00:27, 41.20it/s]\u001b[A\n",
      " 56%|█████▌    | 1392/2500 [00:34<00:26, 41.47it/s]\u001b[A\n",
      " 56%|█████▌    | 1400/2500 [00:34<00:26, 42.15it/s]\u001b[A\n",
      " 56%|█████▋    | 1408/2500 [00:35<00:25, 42.64it/s]\u001b[A\n",
      " 57%|█████▋    | 1416/2500 [00:35<00:25, 42.89it/s]\u001b[A\n",
      " 57%|█████▋    | 1424/2500 [00:35<00:26, 41.08it/s]\u001b[A\n",
      " 57%|█████▋    | 1432/2500 [00:35<00:28, 37.81it/s]\u001b[A\n",
      " 58%|█████▊    | 1440/2500 [00:35<00:28, 36.74it/s]\u001b[A\n",
      " 58%|█████▊    | 1448/2500 [00:36<00:30, 34.70it/s]\u001b[A\n",
      " 58%|█████▊    | 1456/2500 [00:36<00:31, 33.61it/s]\u001b[A\n",
      " 59%|█████▊    | 1464/2500 [00:36<00:31, 32.92it/s]\u001b[A\n",
      " 59%|█████▉    | 1472/2500 [00:36<00:30, 33.45it/s]\u001b[A\n",
      " 59%|█████▉    | 1480/2500 [00:37<00:30, 33.27it/s]\u001b[A\n",
      " 60%|█████▉    | 1488/2500 [00:37<00:30, 33.21it/s]\u001b[A\n",
      " 60%|█████▉    | 1496/2500 [00:37<00:29, 33.64it/s]\u001b[A\n",
      " 60%|██████    | 1504/2500 [00:37<00:29, 34.04it/s]\u001b[A\n",
      " 60%|██████    | 1512/2500 [00:38<00:28, 34.66it/s]\u001b[A\n",
      " 61%|██████    | 1520/2500 [00:38<00:28, 34.79it/s]\u001b[A\n",
      " 61%|██████    | 1528/2500 [00:38<00:29, 32.81it/s]\u001b[A\n",
      " 61%|██████▏   | 1536/2500 [00:38<00:28, 33.76it/s]\u001b[A\n",
      " 62%|██████▏   | 1544/2500 [00:39<00:27, 34.22it/s]\u001b[A\n",
      " 62%|██████▏   | 1552/2500 [00:39<00:27, 34.34it/s]\u001b[A\n",
      " 62%|██████▏   | 1560/2500 [00:39<00:27, 34.06it/s]\u001b[A\n",
      " 63%|██████▎   | 1568/2500 [00:39<00:27, 34.06it/s]\u001b[A\n",
      " 63%|██████▎   | 1576/2500 [00:39<00:26, 34.48it/s]\u001b[A\n",
      " 63%|██████▎   | 1584/2500 [00:40<00:27, 33.89it/s]\u001b[A\n",
      " 64%|██████▎   | 1592/2500 [00:40<00:25, 35.34it/s]\u001b[A\n",
      " 64%|██████▍   | 1600/2500 [00:40<00:25, 35.32it/s]\u001b[A\n",
      " 64%|██████▍   | 1608/2500 [00:40<00:24, 36.70it/s]\u001b[A\n",
      " 65%|██████▍   | 1616/2500 [00:40<00:23, 38.03it/s]\u001b[A\n",
      " 65%|██████▍   | 1624/2500 [00:41<00:22, 38.58it/s]\u001b[A\n",
      " 65%|██████▌   | 1632/2500 [00:41<00:22, 38.64it/s]\u001b[A\n",
      " 66%|██████▌   | 1640/2500 [00:41<00:21, 40.19it/s]\u001b[A\n",
      " 66%|██████▌   | 1648/2500 [00:41<00:20, 41.44it/s]\u001b[A\n",
      " 66%|██████▌   | 1656/2500 [00:41<00:20, 41.39it/s]\u001b[A\n",
      " 67%|██████▋   | 1664/2500 [00:42<00:20, 40.49it/s]\u001b[A\n",
      " 67%|██████▋   | 1672/2500 [00:42<00:21, 38.90it/s]\u001b[A\n",
      " 67%|██████▋   | 1680/2500 [00:42<00:21, 38.24it/s]\u001b[A\n",
      " 68%|██████▊   | 1688/2500 [00:42<00:20, 39.23it/s]\u001b[A\n",
      " 68%|██████▊   | 1696/2500 [00:42<00:19, 40.31it/s]\u001b[A\n",
      " 68%|██████▊   | 1704/2500 [00:43<00:19, 40.85it/s]\u001b[A\n",
      " 68%|██████▊   | 1712/2500 [00:43<00:19, 40.01it/s]\u001b[A\n",
      " 69%|██████▉   | 1720/2500 [00:43<00:19, 40.69it/s]\u001b[A\n",
      " 69%|██████▉   | 1728/2500 [00:43<00:19, 40.59it/s]\u001b[A\n",
      " 69%|██████▉   | 1736/2500 [00:43<00:18, 40.31it/s]\u001b[A\n",
      " 70%|██████▉   | 1744/2500 [00:44<00:18, 41.04it/s]\u001b[A\n",
      " 70%|███████   | 1752/2500 [00:44<00:18, 39.72it/s]\u001b[A\n",
      " 70%|███████   | 1760/2500 [00:44<00:18, 38.96it/s]\u001b[A\n",
      " 71%|███████   | 1768/2500 [00:44<00:18, 38.91it/s]\u001b[A\n",
      " 71%|███████   | 1776/2500 [00:45<00:19, 36.59it/s]\u001b[A\n",
      " 71%|███████▏  | 1784/2500 [00:45<00:19, 37.15it/s]\u001b[A\n",
      " 72%|███████▏  | 1792/2500 [00:45<00:19, 35.81it/s]\u001b[A\n",
      " 72%|███████▏  | 1800/2500 [00:45<00:19, 35.88it/s]\u001b[A\n",
      " 72%|███████▏  | 1808/2500 [00:45<00:18, 37.28it/s]\u001b[A\n",
      " 73%|███████▎  | 1816/2500 [00:46<00:17, 38.78it/s]\u001b[A\n",
      " 73%|███████▎  | 1824/2500 [00:46<00:17, 38.95it/s]\u001b[A\n",
      " 73%|███████▎  | 1832/2500 [00:46<00:16, 39.41it/s]\u001b[A\n",
      " 74%|███████▎  | 1840/2500 [00:46<00:16, 41.02it/s]\u001b[A\n",
      " 74%|███████▍  | 1848/2500 [00:46<00:15, 41.78it/s]\u001b[A\n",
      " 74%|███████▍  | 1856/2500 [00:47<00:15, 42.02it/s]\u001b[A\n",
      " 75%|███████▍  | 1864/2500 [00:47<00:15, 42.38it/s]\u001b[A\n",
      " 75%|███████▍  | 1872/2500 [00:47<00:15, 39.61it/s]\u001b[A\n",
      " 75%|███████▌  | 1880/2500 [00:47<00:16, 37.58it/s]\u001b[A\n",
      " 76%|███████▌  | 1888/2500 [00:47<00:15, 39.85it/s]\u001b[A\n",
      " 76%|███████▌  | 1896/2500 [00:48<00:14, 41.11it/s]\u001b[A\n",
      " 76%|███████▌  | 1904/2500 [00:48<00:15, 37.84it/s]\u001b[A\n",
      " 76%|███████▋  | 1912/2500 [00:48<00:15, 37.73it/s]\u001b[A\n",
      " 77%|███████▋  | 1920/2500 [00:48<00:14, 39.54it/s]\u001b[A\n",
      " 77%|███████▋  | 1928/2500 [00:48<00:15, 38.06it/s]\u001b[A\n",
      " 77%|███████▋  | 1936/2500 [00:49<00:14, 39.03it/s]\u001b[A\n",
      " 78%|███████▊  | 1944/2500 [00:49<00:13, 40.34it/s]\u001b[A\n",
      " 78%|███████▊  | 1952/2500 [00:49<00:13, 39.88it/s]\u001b[A\n",
      " 78%|███████▊  | 1960/2500 [00:49<00:14, 37.29it/s]\u001b[A\n",
      " 79%|███████▊  | 1968/2500 [00:49<00:14, 37.95it/s]\u001b[A\n",
      " 79%|███████▉  | 1976/2500 [00:50<00:13, 38.80it/s]\u001b[A\n",
      " 79%|███████▉  | 1984/2500 [00:50<00:13, 37.76it/s]\u001b[A\n",
      " 80%|███████▉  | 1992/2500 [00:50<00:13, 36.39it/s]\u001b[A\n",
      " 80%|████████  | 2000/2500 [00:50<00:13, 38.15it/s]\u001b[A\n",
      " 80%|████████  | 2008/2500 [00:51<00:12, 38.75it/s]\u001b[A\n",
      " 81%|████████  | 2016/2500 [00:51<00:12, 39.04it/s]\u001b[A\n",
      " 81%|████████  | 2024/2500 [00:51<00:13, 36.14it/s]\u001b[A\n",
      " 81%|████████▏ | 2032/2500 [00:51<00:12, 38.23it/s]\u001b[A\n",
      " 82%|████████▏ | 2040/2500 [00:51<00:11, 39.54it/s]\u001b[A\n",
      " 82%|████████▏ | 2048/2500 [00:52<00:11, 40.69it/s]\u001b[A\n",
      " 82%|████████▏ | 2056/2500 [00:52<00:11, 39.01it/s]\u001b[A\n",
      " 83%|████████▎ | 2064/2500 [00:52<00:10, 39.78it/s]\u001b[A\n",
      " 83%|████████▎ | 2072/2500 [00:52<00:10, 40.19it/s]\u001b[A\n",
      " 83%|████████▎ | 2080/2500 [00:52<00:10, 40.06it/s]\u001b[A\n",
      " 84%|████████▎ | 2088/2500 [00:53<00:10, 38.73it/s]\u001b[A\n",
      " 84%|████████▍ | 2096/2500 [00:53<00:10, 38.25it/s]\u001b[A\n",
      " 84%|████████▍ | 2104/2500 [00:53<00:10, 36.60it/s]\u001b[A\n",
      " 84%|████████▍ | 2112/2500 [00:53<00:10, 38.63it/s]\u001b[A\n",
      " 85%|████████▍ | 2120/2500 [00:53<00:09, 39.51it/s]\u001b[A\n",
      " 85%|████████▌ | 2128/2500 [00:54<00:09, 40.60it/s]\u001b[A\n",
      " 85%|████████▌ | 2136/2500 [00:54<00:09, 38.17it/s]\u001b[A\n",
      " 86%|████████▌ | 2144/2500 [00:54<00:09, 38.67it/s]\u001b[A\n",
      " 86%|████████▌ | 2152/2500 [00:54<00:08, 40.10it/s]\u001b[A\n",
      " 86%|████████▋ | 2160/2500 [00:54<00:08, 40.91it/s]\u001b[A\n",
      " 87%|████████▋ | 2168/2500 [00:55<00:08, 37.85it/s]\u001b[A\n",
      " 87%|████████▋ | 2176/2500 [00:55<00:08, 38.32it/s]\u001b[A\n",
      " 87%|████████▋ | 2184/2500 [00:55<00:08, 39.01it/s]\u001b[A\n",
      " 88%|████████▊ | 2192/2500 [00:55<00:08, 38.11it/s]\u001b[A\n",
      " 88%|████████▊ | 2200/2500 [00:55<00:07, 39.68it/s]\u001b[A\n",
      " 88%|████████▊ | 2208/2500 [00:56<00:07, 40.72it/s]\u001b[A\n",
      " 89%|████████▊ | 2216/2500 [00:56<00:06, 41.48it/s]\u001b[A\n",
      " 89%|████████▉ | 2224/2500 [00:56<00:06, 40.71it/s]\u001b[A\n",
      " 89%|████████▉ | 2232/2500 [00:56<00:06, 38.88it/s]\u001b[A\n",
      " 90%|████████▉ | 2240/2500 [00:56<00:06, 40.33it/s]\u001b[A\n",
      " 90%|████████▉ | 2248/2500 [00:57<00:06, 41.08it/s]\u001b[A\n",
      " 90%|█████████ | 2256/2500 [00:57<00:06, 39.51it/s]\u001b[A\n",
      " 91%|█████████ | 2264/2500 [00:57<00:05, 40.17it/s]\u001b[A\n",
      " 91%|█████████ | 2272/2500 [00:57<00:05, 41.25it/s]\u001b[A\n",
      " 91%|█████████ | 2280/2500 [00:57<00:05, 38.46it/s]\u001b[A\n",
      " 92%|█████████▏| 2288/2500 [00:58<00:05, 38.40it/s]\u001b[A\n",
      " 92%|█████████▏| 2296/2500 [00:58<00:05, 37.78it/s]\u001b[A\n",
      " 92%|█████████▏| 2304/2500 [00:58<00:05, 37.43it/s]\u001b[A\n",
      " 92%|█████████▏| 2312/2500 [00:58<00:04, 38.55it/s]\u001b[A\n",
      " 93%|█████████▎| 2320/2500 [00:58<00:04, 38.89it/s]\u001b[A\n",
      " 93%|█████████▎| 2328/2500 [00:59<00:04, 39.21it/s]\u001b[A\n",
      " 93%|█████████▎| 2336/2500 [00:59<00:04, 39.26it/s]\u001b[A\n",
      " 94%|█████████▍| 2344/2500 [00:59<00:03, 40.16it/s]\u001b[A\n",
      " 94%|█████████▍| 2352/2500 [00:59<00:03, 40.63it/s]\u001b[A\n",
      " 94%|█████████▍| 2360/2500 [00:59<00:03, 40.23it/s]\u001b[A\n",
      " 95%|█████████▍| 2368/2500 [01:00<00:03, 40.28it/s]\u001b[A\n",
      " 95%|█████████▌| 2376/2500 [01:00<00:03, 39.41it/s]\u001b[A\n",
      " 95%|█████████▌| 2384/2500 [01:00<00:02, 39.67it/s]\u001b[A\n",
      " 96%|█████████▌| 2392/2500 [01:00<00:02, 39.91it/s]\u001b[A\n",
      " 96%|█████████▌| 2400/2500 [01:00<00:02, 40.41it/s]\u001b[A\n",
      " 96%|█████████▋| 2408/2500 [01:01<00:02, 40.12it/s]\u001b[A\n",
      " 97%|█████████▋| 2416/2500 [01:01<00:02, 39.60it/s]\u001b[A\n",
      " 97%|█████████▋| 2424/2500 [01:01<00:01, 39.33it/s]\u001b[A\n",
      " 97%|█████████▋| 2432/2500 [01:01<00:01, 38.28it/s]\u001b[A\n",
      " 98%|█████████▊| 2440/2500 [01:02<00:01, 33.40it/s]\u001b[A\n",
      " 98%|█████████▊| 2448/2500 [01:02<00:01, 36.16it/s]\u001b[A\n",
      " 98%|█████████▊| 2456/2500 [01:02<00:01, 36.99it/s]\u001b[A\n",
      " 99%|█████████▊| 2464/2500 [01:02<00:00, 39.48it/s]\u001b[A\n",
      " 99%|█████████▉| 2472/2500 [01:02<00:00, 41.13it/s]\u001b[A\n",
      " 99%|█████████▉| 2480/2500 [01:03<00:00, 42.39it/s]\u001b[A\n",
      "100%|█████████▉| 2488/2500 [01:03<00:00, 42.60it/s]\u001b[A\n",
      "100%|█████████▉| 2496/2500 [01:03<00:00, 41.86it/s]\u001b[A\n",
      "2504it [01:03, 42.04it/s]                          \u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GANbalancer(auxiliary=False, batch_size=128, categorical=None,\n",
       "      critic_iterations=5, critic_layers=[6, 6], generator_input=6,\n",
       "      generator_layers=None, idx_cont=range(0, 6),\n",
       "      learning_rate=[0.005, 0.005], n_iter=2500, random_state=None,\n",
       "      sampling_strategy={0: 5000, 1: 0}, verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_balancer._fit(data[\"Independent\"][0], y=np.zeros(shape=N_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 8/20000 [00:00<08:16, 40.25it/s]\u001b[A\n",
      "  0%|          | 16/20000 [00:00<08:05, 41.15it/s]\u001b[A\n",
      "  0%|          | 24/20000 [00:00<07:59, 41.66it/s]\u001b[A\n",
      "  0%|          | 32/20000 [00:00<07:47, 42.71it/s]\u001b[A\n",
      "  0%|          | 40/20000 [00:00<07:48, 42.59it/s]\u001b[A\n",
      "  0%|          | 48/20000 [00:01<07:41, 43.20it/s]\u001b[A\n",
      "  0%|          | 56/20000 [00:01<07:38, 43.53it/s]\u001b[A\n",
      "  0%|          | 64/20000 [00:01<07:37, 43.56it/s]\u001b[A\n",
      "  0%|          | 72/20000 [00:01<08:04, 41.11it/s]\u001b[A\n",
      "  0%|          | 80/20000 [00:01<08:31, 38.97it/s]\u001b[A\n",
      "  0%|          | 88/20000 [00:02<08:42, 38.10it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-17050e6c9282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan_balancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Independent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_SAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/GANbalanced/code/wgan/imblearn.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, X, n_iter, y)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_iterations\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mtemp_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/GANbalanced/code/wgan/training.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_critic_train_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;31m# Only update generator every |critic_iterations| iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcritic_iterations\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/GANbalanced/code/wgan/training.py\u001b[0m in \u001b[0;36m_critic_train_iteration\u001b[0;34m(self, data, aux_data)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Calculate critic output of real and fake data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0md_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Get gradient penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan_balancer._update(data[\"Independent\"][0], y=np.zeros(shape=N_SAMPLES), n_iter=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25089228,  0.47209673,  1.39876009,  0.72200784,  0.46966859,\n",
       "         0.59633973],\n",
       "       [-0.24717996,  1.03783178,  1.33793831, -0.39310542, -0.09634806,\n",
       "         0.188816  ],\n",
       "       [-0.25048399,  0.47470175,  1.3969625 ,  0.71795033,  0.47572725,\n",
       "         0.58694405]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_first_moments([data[\"Independent\"][0], \n",
    "                     gan_balancer.generator.sample_data(N_SAMPLES),\n",
    "                     smote._sample(data[\"Independent\"][0], y=np.zeros(shape=N_SAMPLES))[0]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1410,  0.4265,  1.2588,  0.7512,  0.5197,  0.5962],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 88/20000 [00:15<08:42, 38.10it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "list(gan_balancer.generator.parameters())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.98, -0.02, -0.01, -0.  , -0.02,  0.02],\n",
       "        [-0.02,  0.99,  0.  ,  0.01, -0.01, -0.03],\n",
       "        [-0.01,  0.  ,  1.01, -0.  , -0.02,  0.01],\n",
       "        [-0.  ,  0.01, -0.  ,  0.98,  0.01,  0.  ],\n",
       "        [-0.02, -0.01, -0.02,  0.01,  0.98,  0.01],\n",
       "        [ 0.02, -0.03,  0.01,  0.  ,  0.01,  1.03]]),\n",
       " array([[ 0.05, -0.02, -0.01, -0.  ,  0.01, -0.01],\n",
       "        [-0.02,  0.07, -0.01, -0.03, -0.01, -0.  ],\n",
       "        [-0.01, -0.01,  0.1 ,  0.02, -0.03, -0.01],\n",
       "        [-0.  , -0.03,  0.02,  0.09,  0.02,  0.01],\n",
       "        [ 0.01, -0.01, -0.03,  0.02,  0.08,  0.02],\n",
       "        [-0.01, -0.  , -0.01,  0.01,  0.02,  0.06]]),\n",
       " array([[ 0.93, -0.01,  0.  ,  0.01, -0.02,  0.01],\n",
       "        [-0.01,  0.94,  0.01,  0.  , -0.01, -0.02],\n",
       "        [ 0.  ,  0.01,  0.95,  0.01, -0.01,  0.01],\n",
       "        [ 0.01,  0.  ,  0.01,  0.94,  0.01,  0.  ],\n",
       "        [-0.02, -0.01, -0.01,  0.01,  0.92,  0.02],\n",
       "        [ 0.01, -0.02,  0.01,  0.  ,  0.02,  0.98]])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_second_moments([data[\"Independent\"][0], \n",
    "                     gan_balancer.generator.sample_data(N_SAMPLES),\n",
    "                     smote._sample(data[\"Independent\"][0], y=np.zeros(shape=N_SAMPLES))[0]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5282,  0.1634, -0.2819, -0.0361, -0.3050, -0.5281],\n",
       "        [-0.0216,  0.2335, -0.4716, -0.6646,  0.1177,  0.1427],\n",
       "        [ 0.0552, -0.5373,  0.5378, -0.4909, -0.0095, -0.2578],\n",
       "        [-0.2706,  0.2197,  0.1449, -0.1162, -0.7956,  0.0044],\n",
       "        [-0.0421, -0.6806, -0.4364,  0.2075, -0.1207,  0.1700],\n",
       "        [-0.7227, -0.0726, -0.2991, -0.1129,  0.1452, -0.6313]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gan_balancer.generator.parameters())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Normal RVs - Covariance Approximation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = \"Dependent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_balancer._fit(data[data_idx][0], y=np.zeros(shape=N_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_first_moments([data[data_idx][0], \n",
    "                     gan_balancer.generator.sample_data(N_SAMPLES),\n",
    "                     smote._sample(data[data_idx][0], y=np.zeros(shape=N_SAMPLES))[0]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance matrix extimate is very close to true covariance matrix, e.g. \n",
    "TRUE  ([[ 0.21, -0.11, -0.11, -0.14,  0.1 ],\n",
    "        [-0.11,  0.32,  0.08,  0.07, -0.23],\n",
    "        [-0.11,  0.08,  0.13,  0.11, -0.08],\n",
    "        [-0.14,  0.07,  0.11,  0.21, -0.07],\n",
    "        [ 0.1 , -0.23, -0.08, -0.07,  0.24]]),\n",
    "        \n",
    " GAN  ([[ 0.21, -0.09, -0.12, -0.17,  0.11],\n",
    "        [-0.09,  0.23,  0.07,  0.07, -0.14],\n",
    "        [-0.12,  0.07,  0.13,  0.13, -0.06],\n",
    "        [-0.17,  0.07,  0.13,  0.21, -0.06],\n",
    "        [ 0.11, -0.14, -0.06, -0.06,  0.2 ]]),\n",
    "        \n",
    "SMOTE ([[ 0.21, -0.11, -0.11, -0.14,  0.1 ],\n",
    "        [-0.11,  0.32,  0.08,  0.07, -0.23],\n",
    "        [-0.11,  0.08,  0.13,  0.11, -0.08],\n",
    "        [-0.14,  0.07,  0.11,  0.21, -0.07],\n",
    "        [ 0.1 , -0.23, -0.08, -0.07,  0.23]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_second_moments([data[data_idx][0], \n",
    "                     gan_balancer.generator.sample_data(N_SAMPLES),\n",
    "                     smote._sample(data[data_idx][0], y=np.zeros(shape=N_SAMPLES))[0]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critic data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the critic to select samples that are more realistic from a larger set of generated observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gan_balancer.generator(gan_balancer.generator.sample_latent(N_SAMPLES*20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_critic = np.argsort(\n",
    "    gan_balancer.critic(sample).detach().numpy().flatten()\n",
    "                         )\n",
    "idx_lowest = idx_critic[:N_SAMPLES].copy()\n",
    "idx_highest = idx_critic[-N_SAMPLES:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critic output is in the range $[-\\inf;0]$ where higher is less difference to the real distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_np = sample.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lowest = sample_np[idx_lowest,:].copy()\n",
    "sample_random = sample_np[np.random.choice(range(0,N_SAMPLES), size=N_SAMPLES),:].copy()\n",
    "sample_highest = sample_np[idx_highest,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_first_moments([data[\"Independent\"][0], \n",
    "                     sample_highest,\n",
    "                     sample_np,\n",
    "                     sample_lowest\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_second_moments([data[\"Independent\"][0], \n",
    "                     sample_highest,\n",
    "                     sample_np,\n",
    "                     sample_lowest\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = [(x,y) for x in range(no_vars) for y in range(no_vars) if y>x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=no_vars, ncols=no_vars, sharex=True, sharey=True, squeeze=True,figsize=(10,10))\n",
    "for y in axes:\n",
    "    for x in y:\n",
    "        x.set_xticklabels([])\n",
    "        x.set_yticklabels([])\n",
    "\n",
    "for i,j in combinations:\n",
    "    sns.kdeplot(X_majority[:,i], X_majority[:,j], alpha=0.5, cmap=\"Blues\", ax=axes[(j,i)])\n",
    "    sns.kdeplot(X_minority[:,i], X_minority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(j,i)])\n",
    "fig.savefig(f'../img/cont_sample_tr_iter_{trainer.G.training_iterations}.png',format='png', dpi=100)\n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 90\n",
    "\n",
    "for _ in range(30):\n",
    "    trainer.train(data_loader, epochs)\n",
    "    \n",
    "    \n",
    "    if modus == 'full':\n",
    "        fake_minority = generator(*generator.sample_latent(num_samples= 1000, class_index=1)).data.numpy()\n",
    "        fake_majority = generator(*generator.sample_latent(num_samples= 1000, class_index=0)).data.numpy()\n",
    "    elif modus == 'minority':\n",
    "        fake_minority = generator(generator.sample_latent(num_samples= 1000)).data.numpy()\n",
    "        \n",
    "    fig, axes = plt.subplots(nrows=no_vars, ncols=no_vars, sharex=True, squeeze=True,figsize=(10,10))\n",
    "    for y in axes:\n",
    "        for x in y:\n",
    "            x.set_xticklabels([])\n",
    "            x.set_yticklabels([])\n",
    "    \n",
    "    for i in range(no_vars):\n",
    "        sns.kdeplot(X_minority[:,i], alpha=0.5, shade=True, color=\"blue\", ax=axes[(i,i)])\n",
    "        sns.kdeplot(fake_minority[:,i], alpha=0.5, shade=True, color=\"green\", ax=axes[(i,i)])\n",
    "    \n",
    "    for i,j in combinations:\n",
    "        axes[(i,j)].set_ylim(0,1)\n",
    "        # majority (upper right)\n",
    "        if modus == 'full':\n",
    "            sns.kdeplot(X_majority[0:1000,i], X_majority[0:1000,j], alpha=0.5, cmap=\"Blues\", ax=axes[(i,j)])\n",
    "            sns.kdeplot(fake_majority[:,i], fake_majority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(i,j)], )\n",
    "        \n",
    "        # minority (lower left)\n",
    "        sns.kdeplot(X_minority[:,i], X_minority[:,j], alpha=0.5, cmap=\"Blues\", ax=axes[(j,i)])\n",
    "        sns.kdeplot(fake_minority[:,i], fake_minority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(j,i)])\n",
    "        \n",
    "    fig.savefig(f'../img/cont_sample_tr_iter_{trainer.G.training_iterations}.png',format='png', dpi=200)\n",
    "        #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = f\"multinormal_n{N//1000}_k{no_vars}_{modus}\"\n",
    "torch.save(generator.state_dict(), f\"../models/wgan_generator_{desc}_{generator.training_iterations}\")\n",
    "torch.save(discriminator.state_dict(), f\"../models/wgan_discriminator_{desc}_{generator.training_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"multinormal_n10_k4_c2_6999\"\n",
    "generator.load_state_dict(torch.load(f\"../models/wgan_generator_{file_name}\"))\n",
    "discriminator.load_state_dict(torch.load(f\"../models/wgan_discriminator_{file_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_minority = generator(*generator.sample_latent(num_samples= minority_samples, class_index=1)).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_minority, axis=0))\n",
    "print(np.mean(fake_minority, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(X_minority, q=np.arange(0,1,0.1), axis=0))\n",
    "print(np.quantile(fake_minority, q=np.arange(0,1,0.1), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.cov(X_minority, rowvar=False) - np.cov(fake_minority,rowvar=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = X_minority.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = generator(*generator.sample_latent(num_samples= sample_size, class_index=1)).data.numpy()\n",
    "#fake = generator(generator.sample_latent(num_samples= sample_size)).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fakereal = np.vstack([X_minority, \n",
    "                        fake])\n",
    "y_fakereal = np.concatenate([np.zeros(X_minority.shape[0]), \n",
    "                        np.ones(fake.shape[0])]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, min_samples_leaf=20, n_jobs=10)\n",
    "model_fakereal = clf.fit(X_fakereal, y_fakereal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fakereal = model_fakereal.predict_proba(X_fakereal)[:,1]\n",
    "roc_auc_score(y_fakereal, pred_fakereal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive performance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = np.argmax(y_train, axis=1)\n",
    "y_test_bin = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_auc(model_library, X, y_true):\n",
    "    auc = {}\n",
    "    for model in model_library.keys():\n",
    "        pred = model_library[model].predict_proba(X_test)[:,1]\n",
    "        auc[model] = roc_auc_score(y_true, pred)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_samples = X_minority.shape[0]\n",
    "majority_samples = X_majority.shape[0]\n",
    "\n",
    "fake_minority = generator(*generator.sample_latent(num_samples= minority_samples, class_index=1)).data.numpy()\n",
    "fake_majority = generator(*generator.sample_latent(num_samples= majority_samples, class_index=0)).data.numpy()\n",
    "\n",
    "X_synthetic = np.vstack([fake_majority, \n",
    "                         fake_minority])\n",
    "y_synthetic = np.concatenate([np.zeros(majority_samples), \n",
    "                              np.ones(minority_samples)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_org = DecisionTreeClassifier(max_depth=10) #LogisticRegression(solver='saga') \n",
    "clf_fake = DecisionTreeClassifier(max_depth=10) #LogisticRegression(solver='saga')\n",
    "\n",
    "predictive = {}\n",
    "predictive[\"real\"] = clf_org.fit(X=X_train, y=y_train_bin)\n",
    "predictive[\"synthetic\"] = clf_fake.fit(X=X_synthetic, y=y_synthetic)\n",
    "\n",
    "test_auc(predictive, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\"original\":[],\"GANbalanced\":[]}\n",
    "for i in range(200):\n",
    "    sample_size = X_minority.shape[0]*4\n",
    "    X_fake = generator(*generator.sample_latent(num_samples= sample_size, class_index=1)).data.numpy()\n",
    "    #X_fake = generator(generator.sample_latent(num_samples= sample_size, class_index=None)).data.numpy()\n",
    "    y_fake = np.ones(shape=[sample_size])\n",
    "\n",
    "    X_up = np.vstack([X_train,X_fake])\n",
    "    y_up = np.hstack([y_train_bin,y_fake])\n",
    "\n",
    "    clf_org = DecisionTreeClassifier(max_depth=5)\n",
    "    clf_fake = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "    upsampling = {}\n",
    "    upsampling[\"original\"] =  clf_org.fit(X=X_train, y=y_train_bin)\n",
    "    upsampling[\"GANbalanced\"] = clf_fake.fit(X=X_up, y=y_up)\n",
    "    \n",
    "    performance_temp = test_auc(upsampling, X_test, y_test_bin)\n",
    "    for model in performance_temp:\n",
    "        performance[model].append(performance_temp[model])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(performance).mean())\n",
    "print(pd.DataFrame(performance).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_function(X, y, clf, ax):\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.8, c=y, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "plot_decision_function(X_train, y_train, upsampling[\"original\"], ax1)\n",
    "plot_decision_function(X_up, y_up, upsampling[\"GANbalanced\"], ax2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
