{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from experiment.experiment_config import experiment_config\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X,y = make_classification(n_samples=5000, n_features=10, weights=[0.9,0.1], n_informative=10, n_redundant=0, n_clusters_per_class=10)\n",
    "\n",
    "# from wgan.data import load_DMC10\n",
    "# X, _, y, _, idx_cont, idx_cat, cat_dict = load_DMC10(\"/Users/hauptjoh/Data/DMC10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers, models, samplers = experiment_config(X, idx_cont=None, idx_cat=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from lift.perc_lift_score import perc_lift_score\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Samplers\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from wgan.imblearn import GANbalancer\n",
    "\n",
    "idx_cont=None\n",
    "idx_cat = None\n",
    "\n",
    "### Samplers\n",
    "scorers = {'auc':make_scorer(roc_auc_score, needs_proba=True),\n",
    "          'TDLift':make_scorer(perc_lift_score, needs_proba=True, percentile=0.1)}\n",
    "\n",
    "### Models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear'), {\n",
    "    \"C\": [1]\n",
    "}))\n",
    "# models.append(('RF', RandomForestClassifier(), {\n",
    "#     \"n_estimators\":[100],\n",
    "#     \"max_features\":[\"sqrt\"],\n",
    "#     \"min_samples_leaf\":[20]\n",
    "# }))\n",
    "\n",
    "### Samplers\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from wgan.imblearn import GANbalancer\n",
    "\n",
    "\n",
    "samplers = []\n",
    "\n",
    "# baseline\n",
    "samplers.append(('unbalanced', None, {}))\n",
    "\n",
    "# SMOTE\n",
    "samplers.append(('SMOTE', SMOTE(), {\n",
    "    'k_neighbors':[5,10,20]\n",
    "}))\n",
    "\n",
    "# ADASYN\n",
    "samplers.append(('ADASYN', ADASYN(), {\n",
    "    'n_neighbors':[5,10,20]\n",
    "}))\n",
    "\n",
    "# GAN\n",
    "if idx_cont is None:\n",
    "    idx_cont = list(range(X.shape[1]))\n",
    "\n",
    "categorical = None\n",
    "if idx_cat is not None:\n",
    "    categorical = [(i,\n",
    "                    np.max(X[:,i])+1,\n",
    "                    int(min(15., np.ceil(np.max((X[:,i])+1)/2)))\n",
    "                   )\n",
    "                    for i in idx_cat]\n",
    "\n",
    "samplers.append(('cGAN', GANbalancer(\n",
    "        idx_cont=idx_cont, categorical=categorical,\n",
    "        generator_input=X.shape[1]\n",
    "), {\n",
    "    'generator_layers' : [[20,20]],\n",
    "    'critic_layers'    : [[20,20]],\n",
    "    'n_iter'           : [1000,2000,6000,10000,15000]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  2.55it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:01,  1.11it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:05<00:01,  1.50s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [1:26:41<00:00, 5201.76s/it]\u001b[A\n",
      "100%|██████████| 4/4 [1:26:47<00:00, 1561.59s/it]\n"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "\n",
    "score_outer = {}\n",
    "\n",
    "for sampler_name, sampler, sampler_grid in tqdm(samplers):\n",
    "    \n",
    "    sampler_grid = {'sampler__'+key:item for key, item in sampler_grid.items()}\n",
    "    \n",
    "    score_inner = {}\n",
    "\n",
    "    for model_name, model, model_grid in tqdm(models):\n",
    "\n",
    "        pipeline = Pipeline(memory='./.cachedir', steps=[\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('sampler', sampler),\n",
    "            ('classifier', model)\n",
    "          ])\n",
    "        model_grid = {'classifier__'+key:item for key, item in model_grid.items()}\n",
    "        p_grid = {**sampler_grid, **model_grid}\n",
    "        \n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        outer_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "            \n",
    "        clf = GridSearchCV(pipeline, param_grid= p_grid, cv=inner_cv, scoring=scorers, refit='auc', \n",
    "                           return_train_score=True, iid=False, n_jobs=3)\n",
    "\n",
    "        score_inner[model_name] = cross_validate(clf, X=X,y=y,cv=outer_cv , scoring=scorers, return_train_score=True,\n",
    "                                    return_estimator=True)\n",
    "    score_outer[sampler_name] = score_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc    auc_sd   lift0.1  lift0.1_sd model     sampler\n",
      "0  0.661829  0.016844  1.070364    0.006128    LR  unbalanced\n",
      "1  0.670366  0.014031  1.072507    0.012529    LR       SMOTE\n",
      "2  0.671946  0.014659  1.070371    0.010393    LR      ADASYN\n",
      "3  0.597118  0.033858  1.025555    0.013139    LR        cGAN\n"
     ]
    }
   ],
   "source": [
    "scores = pd.DataFrame([{\n",
    "  'sampler':sampler_name, 'model':model_name, \n",
    "    'auc':np.mean(model[\"test_auc\"]),  'auc_sd':np.std(model[\"test_auc\"]),\n",
    "    'lift0.1':np.mean(model[\"test_TDLift\"]),  'lift0.1_sd':np.std(model[\"test_TDLift\"]),\n",
    "} for sampler_name, sampler in score_outer.items()\n",
    "    for model_name, model in sampler.items()]\n",
    ")\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0542058 , 0.04649496, 0.05619779]),\n",
       " 'std_fit_time': array([0.00973518, 0.00063056, 0.00939692]),\n",
       " 'mean_score_time': array([0.00349998, 0.00264945, 0.00263748]),\n",
       " 'std_score_time': array([0.00162883, 0.00036672, 0.00025601]),\n",
       " 'param_classifier__C': masked_array(data=[1, 1, 1],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_sampler__k_neighbors': masked_array(data=[5, 10, 20],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__C': 1, 'sampler__k_neighbors': 5},\n",
       "  {'classifier__C': 1, 'sampler__k_neighbors': 10},\n",
       "  {'classifier__C': 1, 'sampler__k_neighbors': 20}],\n",
       " 'split0_test_auc': array([0.6978022 , 0.70535714, 0.69767342]),\n",
       " 'split1_test_auc': array([0.68187672, 0.67582418, 0.67955872]),\n",
       " 'split2_test_auc': array([0.66728194, 0.66702438, 0.66848386]),\n",
       " 'split3_test_auc': array([0.66084306, 0.66642342, 0.66848386]),\n",
       " 'split4_test_auc': array([0.68774738, 0.70973154, 0.68968336]),\n",
       " 'mean_test_auc': array([0.67911026, 0.68487213, 0.68077664]),\n",
       " 'std_test_auc': array([0.01345542, 0.01885942, 0.01156321]),\n",
       " 'rank_test_auc': array([3, 1, 2], dtype=int32),\n",
       " 'split0_train_auc': array([0.68642357, 0.69168492, 0.68946495]),\n",
       " 'split1_train_auc': array([0.69774353, 0.69670736, 0.69816497]),\n",
       " 'split2_train_auc': array([0.70080101, 0.70265322, 0.70455107]),\n",
       " 'split3_train_auc': array([0.70001718, 0.69884411, 0.69909644]),\n",
       " 'split4_train_auc': array([0.69186234, 0.68833974, 0.69008628]),\n",
       " 'mean_train_auc': array([0.69536953, 0.69564587, 0.69627274]),\n",
       " 'std_train_auc': array([0.00546019, 0.00508974, 0.00573939]),\n",
       " 'split0_test_TDLift': array([1.08974359, 1.08974359, 1.08974359]),\n",
       " 'split1_test_TDLift': array([1.11111111, 1.11111111, 1.11111111]),\n",
       " 'split2_test_TDLift': array([1.06837607, 1.06837607, 1.06837607]),\n",
       " 'split3_test_TDLift': array([1.06837607, 1.06837607, 1.06837607]),\n",
       " 'split4_test_TDLift': array([1.0875641 , 1.0875641 , 1.06623932]),\n",
       " 'mean_test_TDLift': array([1.08503419, 1.08503419, 1.08076923]),\n",
       " 'std_test_TDLift': array([0.01589699, 0.01589699, 0.01743255]),\n",
       " 'rank_test_TDLift': array([1, 1, 3], dtype=int32),\n",
       " 'split0_train_TDLift': array([1.08385951, 1.0785203 , 1.0785203 ]),\n",
       " 'split1_train_TDLift': array([1.06784188, 1.07318109, 1.06784188]),\n",
       " 'split2_train_TDLift': array([1.08385951, 1.0785203 , 1.07318109]),\n",
       " 'split3_train_TDLift': array([1.08385951, 1.08385951, 1.08385951]),\n",
       " 'split4_train_TDLift': array([1.07905983, 1.08440171, 1.08440171]),\n",
       " 'mean_train_TDLift': array([1.07969605, 1.07969658, 1.0775609 ]),\n",
       " 'std_train_TDLift': array([0.00621175, 0.00411551, 0.00634085])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67911026, 0.68487213, 0.68077664])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['mean_test_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.6978022 , 0.70535714, 0.69767342]),\n",
       " array([0.68187672, 0.67582418, 0.67955872]),\n",
       " array([0.66728194, 0.66702438, 0.66848386]),\n",
       " array([0.66084306, 0.66642342, 0.66848386]),\n",
       " array([0.68774738, 0.70973154, 0.68968336]),\n",
       " array([0.67911026, 0.68487213, 0.68077664]),\n",
       " array([0.01345542, 0.01885942, 0.01156321]),\n",
       " array([3, 1, 2], dtype=int32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[value for key,value in temp.items() if \"test_auc\" in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = score_outer['unbalanced'][\"LR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['classifier__C', 'sampler__k_neighbors'])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_outer['SMOTE'][\"LR\"]['estimator'][0].cv_results_['params'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({\"Model\":[\"LR\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x1a28d1b6a0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupby(['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': {'fit_time': array([1.00116801, 1.01145983]),\n",
       "  'score_time': array([0.00440621, 0.00404525]),\n",
       "  'estimator': (GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory='./.cachedir',\n",
       "        steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('sampler', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
       "      out_step='deprecated', random_state=None, ratio=None,\n",
       "      sampling_strategy='auto', svm_estimator='deprecated')), ('classifier', LogisticRegress...ty='l2', random_state=None, solver='liblinear',\n",
       "             tol=0.0001, verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid=False, n_jobs=3,\n",
       "          param_grid={'sampler__k_neighbors': [5, 10, 20], 'classifier__C': [1]},\n",
       "          pre_dispatch='2*n_jobs', refit='auc', return_train_score=True,\n",
       "          scoring={'auc': make_scorer(roc_auc_score, needs_proba=True), 'TDLift': make_scorer(perc_lift_score, needs_proba=True, percentile=0.1)},\n",
       "          verbose=0),\n",
       "   GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory='./.cachedir',\n",
       "        steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('sampler', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
       "      out_step='deprecated', random_state=None, ratio=None,\n",
       "      sampling_strategy='auto', svm_estimator='deprecated')), ('classifier', LogisticRegress...ty='l2', random_state=None, solver='liblinear',\n",
       "             tol=0.0001, verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid=False, n_jobs=3,\n",
       "          param_grid={'sampler__k_neighbors': [5, 10, 20], 'classifier__C': [1]},\n",
       "          pre_dispatch='2*n_jobs', refit='auc', return_train_score=True,\n",
       "          scoring={'auc': make_scorer(roc_auc_score, needs_proba=True), 'TDLift': make_scorer(perc_lift_score, needs_proba=True, percentile=0.1)},\n",
       "          verbose=0)),\n",
       "  'test_auc': array([0.65633552, 0.68439722]),\n",
       "  'train_auc': array([0.69591335, 0.65797756]),\n",
       "  'test_TDLift': array([1.05997845, 1.0850359 ]),\n",
       "  'train_TDLift': array([1.08930769, 1.05997845])}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " score_outer['SMOTE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp  = pd.concat([ \n",
    "# Inner CV tuning results as DataFrame\n",
    "pd.concat([pd.DataFrame(inner_cv.cv_results_['params'], dtype='str'), \n",
    "           pd.DataFrame({\n",
    "               'mean_test_auc':inner_cv.cv_results_['mean_test_auc'],\n",
    "               'std_test_auc':inner_cv.cv_results_['std_test_auc'],\n",
    "               'mean_test_TDLift':inner_cv.cv_results_['mean_test_TDLift'],\n",
    "               'std_test_TDLift':inner_cv.cv_results_['std_test_TDLift']\n",
    "           })\n",
    "          ], sort=False, ignore_index=False, axis=1)\n",
    "for inner_cv in model['estimator']]).groupby(list(model['estimator'][0].cv_results_['params'][0].keys())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier__C']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model['estimator'][0].cv_results_['params'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>mean_test_TDLift</th>\n",
       "      <th>std_test_TDLift</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier__C</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.630473</td>\n",
       "      <td>0.027994</td>\n",
       "      <td>1.057617</td>\n",
       "      <td>0.031181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_test_auc  std_test_auc  mean_test_TDLift  std_test_TDLift\n",
       "classifier__C                                                                \n",
       "1                   0.630473      0.027994          1.057617         0.031181"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.so#.groupby(['classifier__C','sampler__k_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[10]'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = {sampler_name:\n",
    "    {model_name:\n",
    "    # vstack result DataFrame for each outer fold\n",
    "        pd.concat([ \n",
    "            # Inner CV tuning results as DataFrame\n",
    "            pd.concat([pd.DataFrame(inner_cv.cv_results_['params']).astype(str), \n",
    "                       pd.DataFrame({\n",
    "                           'mean_test_auc':inner_cv.cv_results_['mean_test_auc'],\n",
    "                           'std_test_auc':inner_cv.cv_results_['std_test_auc'],\n",
    "                           'mean_test_TDLift':inner_cv.cv_results_['mean_test_TDLift'],\n",
    "                           'std_test_TDLift':inner_cv.cv_results_['std_test_TDLift']\n",
    "                       })\n",
    "                      ], sort=False, ignore_index=False, axis=1)\n",
    "            for inner_cv in model['estimator']]).groupby(list(model['estimator'][0].cv_results_['params'][0].keys())).mean().reset_index()\n",
    "            for model_name, model in sampler.items()}\n",
    "          for sampler_name, sampler in score_outer.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier__C</th>\n",
       "      <th>sampler__critic_layers</th>\n",
       "      <th>sampler__generator_layers</th>\n",
       "      <th>sampler__n_iter</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>mean_test_TDLift</th>\n",
       "      <th>std_test_TDLift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.527235</td>\n",
       "      <td>0.082427</td>\n",
       "      <td>1.019196</td>\n",
       "      <td>0.037761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.578513</td>\n",
       "      <td>0.050765</td>\n",
       "      <td>1.030048</td>\n",
       "      <td>0.043520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.594508</td>\n",
       "      <td>0.064937</td>\n",
       "      <td>1.038586</td>\n",
       "      <td>0.043547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.511375</td>\n",
       "      <td>0.035972</td>\n",
       "      <td>0.991504</td>\n",
       "      <td>0.061659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.084654</td>\n",
       "      <td>0.974537</td>\n",
       "      <td>0.052733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier__C sampler__critic_layers sampler__generator_layers  \\\n",
       "0             1                   [20]                      [20]   \n",
       "1             1                   [20]                      [20]   \n",
       "2             1                   [20]                      [20]   \n",
       "3             1                   [20]                      [20]   \n",
       "4             1                   [20]                      [20]   \n",
       "\n",
       "  sampler__n_iter  mean_test_auc  std_test_auc  mean_test_TDLift  \\\n",
       "0            1000       0.527235      0.082427          1.019196   \n",
       "1           10000       0.578513      0.050765          1.030048   \n",
       "2           15000       0.594508      0.064937          1.038586   \n",
       "3            2000       0.511375      0.035972          0.991504   \n",
       "4            6000       0.499183      0.084654          0.974537   \n",
       "\n",
       "   std_test_TDLift  \n",
       "0         0.037761  \n",
       "1         0.043520  \n",
       "2         0.043547  \n",
       "3         0.061659  \n",
       "4         0.052733  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_results[\"cGAN\"][\"LR\"].sort_values([\"sampler__n_iter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classifier__C']\n",
      "['classifier__C']\n",
      "['classifier__C', 'sampler__k_neighbors']\n",
      "['classifier__C', 'sampler__k_neighbors']\n",
      "['classifier__C', 'sampler__n_neighbors']\n",
      "['classifier__C', 'sampler__n_neighbors']\n",
      "['classifier__C', 'sampler__critic_layers', 'sampler__generator_layers', 'sampler__n_iter']\n",
      "['classifier__C', 'sampler__critic_layers', 'sampler__generator_layers', 'sampler__n_iter']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'unbalanced': {'LR': [None, None]},\n",
       " 'SMOTE': {'LR': [None, None]},\n",
       " 'ADASYN': {'LR': [None, None]},\n",
       " 'cGAN': {'LR': [None, None]}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{sampler_name:\n",
    "    {model_name:\n",
    "    # vstack result DataFrame for each outer fold\n",
    "        [ \n",
    "            # Inner CV tuning results as DataFrame\n",
    "            print(list(inner_cv.cv_results_['params'][0].keys()))\n",
    "            for inner_cv in model['estimator']]\n",
    "            for model_name, model in sampler.items()}\n",
    "          for sampler_name, sampler in score_outer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_scores =  pd.DataFrame([{\n",
    "  'sampler':sampler_name, 'model':model_name,\n",
    "    'parameter':param_name,\n",
    "    'parameter_value':str(param_value),\n",
    "    'auc':cv.cv_results_['mean_test_auc'][i],  'auc_sd':cv.cv_results_[\"std_test_auc\"][i],\n",
    "    'lift0.1':cv.cv_results_[\"mean_test_TDLift\"][i],  'lift0.1_sd':cv.cv_results_[\"std_test_TDLift\"][i]\n",
    "}   for sampler_name, sampler in score_outer.items()\n",
    "    for model_name, model in sampler.items()\n",
    "    for cv in model['estimator']\n",
    "    for i, (param_name, param_value) in enumerate(cv.cv_results_['params'][0].items())\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_sd</th>\n",
       "      <th>lift0.1</th>\n",
       "      <th>lift0.1_sd</th>\n",
       "      <th>model</th>\n",
       "      <th>parameter</th>\n",
       "      <th>parameter_value</th>\n",
       "      <th>sampler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666012</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>1.072222</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>LR</td>\n",
       "      <td>classifier__C</td>\n",
       "      <td>1</td>\n",
       "      <td>unbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.594935</td>\n",
       "      <td>0.041543</td>\n",
       "      <td>1.043012</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>LR</td>\n",
       "      <td>classifier__C</td>\n",
       "      <td>1</td>\n",
       "      <td>unbalanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.679110</td>\n",
       "      <td>0.013455</td>\n",
       "      <td>1.085034</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>LR</td>\n",
       "      <td>classifier__C</td>\n",
       "      <td>1</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684872</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>1.085034</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__k_neighbors</td>\n",
       "      <td>5</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.627644</td>\n",
       "      <td>0.050939</td>\n",
       "      <td>1.043012</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>LR</td>\n",
       "      <td>classifier__C</td>\n",
       "      <td>1</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.627536</td>\n",
       "      <td>0.054787</td>\n",
       "      <td>1.047286</td>\n",
       "      <td>0.026814</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__k_neighbors</td>\n",
       "      <td>5</td>\n",
       "      <td>SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.680049</td>\n",
       "      <td>0.015360</td>\n",
       "      <td>1.089308</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>LR</td>\n",
       "      <td>classifier__C</td>\n",
       "      <td>1</td>\n",
       "      <td>ADASYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.682259</td>\n",
       "      <td>0.016651</td>\n",
       "      <td>1.080761</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__n_neighbors</td>\n",
       "      <td>5</td>\n",
       "      <td>ADASYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.626590</td>\n",
       "      <td>0.053930</td>\n",
       "      <td>1.047286</td>\n",
       "      <td>0.030027</td>\n",
       "      <td>LR</td>\n",
       "      <td>classifier__C</td>\n",
       "      <td>1</td>\n",
       "      <td>ADASYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.629165</td>\n",
       "      <td>0.050968</td>\n",
       "      <td>1.043012</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__n_neighbors</td>\n",
       "      <td>5</td>\n",
       "      <td>ADASYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.535233</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>1.020940</td>\n",
       "      <td>0.027643</td>\n",
       "      <td>LR</td>\n",
       "      <td>classifier__C</td>\n",
       "      <td>1</td>\n",
       "      <td>cGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.522762</td>\n",
       "      <td>0.053160</td>\n",
       "      <td>0.986761</td>\n",
       "      <td>0.052565</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__critic_layers</td>\n",
       "      <td>[20]</td>\n",
       "      <td>cGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.534925</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>1.020957</td>\n",
       "      <td>0.047558</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__generator_layers</td>\n",
       "      <td>[20]</td>\n",
       "      <td>cGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.572878</td>\n",
       "      <td>0.039617</td>\n",
       "      <td>1.055137</td>\n",
       "      <td>0.029120</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__n_iter</td>\n",
       "      <td>1000</td>\n",
       "      <td>cGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.519237</td>\n",
       "      <td>0.093292</td>\n",
       "      <td>1.017453</td>\n",
       "      <td>0.047879</td>\n",
       "      <td>LR</td>\n",
       "      <td>classifier__C</td>\n",
       "      <td>1</td>\n",
       "      <td>cGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.996248</td>\n",
       "      <td>0.070753</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__critic_layers</td>\n",
       "      <td>[20]</td>\n",
       "      <td>cGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.463440</td>\n",
       "      <td>0.090604</td>\n",
       "      <td>0.928117</td>\n",
       "      <td>0.057908</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__generator_layers</td>\n",
       "      <td>[20]</td>\n",
       "      <td>cGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.584149</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>1.004958</td>\n",
       "      <td>0.057920</td>\n",
       "      <td>LR</td>\n",
       "      <td>sampler__n_iter</td>\n",
       "      <td>1000</td>\n",
       "      <td>cGAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         auc    auc_sd   lift0.1  lift0.1_sd model                  parameter  \\\n",
       "0   0.666012  0.014444  1.072222    0.021040    LR              classifier__C   \n",
       "1   0.594935  0.041543  1.043012    0.041322    LR              classifier__C   \n",
       "2   0.679110  0.013455  1.085034    0.015897    LR              classifier__C   \n",
       "3   0.684872  0.018859  1.085034    0.015897    LR       sampler__k_neighbors   \n",
       "4   0.627644  0.050939  1.043012    0.024734    LR              classifier__C   \n",
       "5   0.627536  0.054787  1.047286    0.026814    LR       sampler__k_neighbors   \n",
       "6   0.680049  0.015360  1.089308    0.019132    LR              classifier__C   \n",
       "7   0.682259  0.016651  1.080761    0.021637    LR       sampler__n_neighbors   \n",
       "8   0.626590  0.053930  1.047286    0.030027    LR              classifier__C   \n",
       "9   0.629165  0.050968  1.043012    0.031257    LR       sampler__n_neighbors   \n",
       "10  0.535233  0.071561  1.020940    0.027643    LR              classifier__C   \n",
       "11  0.522762  0.053160  0.986761    0.052565    LR     sampler__critic_layers   \n",
       "12  0.534925  0.078704  1.020957    0.047558    LR  sampler__generator_layers   \n",
       "13  0.572878  0.039617  1.055137    0.029120    LR            sampler__n_iter   \n",
       "14  0.519237  0.093292  1.017453    0.047879    LR              classifier__C   \n",
       "15  0.499989  0.018784  0.996248    0.070753    LR     sampler__critic_layers   \n",
       "16  0.463440  0.090604  0.928117    0.057908    LR  sampler__generator_layers   \n",
       "17  0.584149  0.061914  1.004958    0.057920    LR            sampler__n_iter   \n",
       "\n",
       "   parameter_value     sampler  \n",
       "0                1  unbalanced  \n",
       "1                1  unbalanced  \n",
       "2                1       SMOTE  \n",
       "3                5       SMOTE  \n",
       "4                1       SMOTE  \n",
       "5                5       SMOTE  \n",
       "6                1      ADASYN  \n",
       "7                5      ADASYN  \n",
       "8                1      ADASYN  \n",
       "9                5      ADASYN  \n",
       "10               1        cGAN  \n",
       "11            [20]        cGAN  \n",
       "12            [20]        cGAN  \n",
       "13            1000        cGAN  \n",
       "14               1        cGAN  \n",
       "15            [20]        cGAN  \n",
       "16            [20]        cGAN  \n",
       "17            1000        cGAN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_sd</th>\n",
       "      <th>lift0.1</th>\n",
       "      <th>lift0.1_sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampler</th>\n",
       "      <th>model</th>\n",
       "      <th>parameter</th>\n",
       "      <th>parameter_value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ADASYN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR</th>\n",
       "      <th>classifier__C</th>\n",
       "      <th>1</th>\n",
       "      <td>0.653320</td>\n",
       "      <td>0.034645</td>\n",
       "      <td>1.068297</td>\n",
       "      <td>0.024579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampler__n_neighbors</th>\n",
       "      <th>5</th>\n",
       "      <td>0.655712</td>\n",
       "      <td>0.033809</td>\n",
       "      <td>1.061886</td>\n",
       "      <td>0.026447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SMOTE</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR</th>\n",
       "      <th>classifier__C</th>\n",
       "      <th>1</th>\n",
       "      <td>0.653377</td>\n",
       "      <td>0.032197</td>\n",
       "      <td>1.064023</td>\n",
       "      <td>0.020316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampler__k_neighbors</th>\n",
       "      <th>5</th>\n",
       "      <td>0.656204</td>\n",
       "      <td>0.036823</td>\n",
       "      <td>1.066160</td>\n",
       "      <td>0.021355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">cGAN</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">LR</th>\n",
       "      <th>classifier__C</th>\n",
       "      <th>1</th>\n",
       "      <td>0.527235</td>\n",
       "      <td>0.082427</td>\n",
       "      <td>1.019196</td>\n",
       "      <td>0.037761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampler__critic_layers</th>\n",
       "      <th>[20]</th>\n",
       "      <td>0.511375</td>\n",
       "      <td>0.035972</td>\n",
       "      <td>0.991504</td>\n",
       "      <td>0.061659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampler__generator_layers</th>\n",
       "      <th>[20]</th>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.084654</td>\n",
       "      <td>0.974537</td>\n",
       "      <td>0.052733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampler__n_iter</th>\n",
       "      <th>1000</th>\n",
       "      <td>0.578513</td>\n",
       "      <td>0.050765</td>\n",
       "      <td>1.030048</td>\n",
       "      <td>0.043520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unbalanced</th>\n",
       "      <th>LR</th>\n",
       "      <th>classifier__C</th>\n",
       "      <th>1</th>\n",
       "      <td>0.630473</td>\n",
       "      <td>0.027994</td>\n",
       "      <td>1.057617</td>\n",
       "      <td>0.031181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 auc  \\\n",
       "sampler    model parameter                 parameter_value             \n",
       "ADASYN     LR    classifier__C             1                0.653320   \n",
       "                 sampler__n_neighbors      5                0.655712   \n",
       "SMOTE      LR    classifier__C             1                0.653377   \n",
       "                 sampler__k_neighbors      5                0.656204   \n",
       "cGAN       LR    classifier__C             1                0.527235   \n",
       "                 sampler__critic_layers    [20]             0.511375   \n",
       "                 sampler__generator_layers [20]             0.499183   \n",
       "                 sampler__n_iter           1000             0.578513   \n",
       "unbalanced LR    classifier__C             1                0.630473   \n",
       "\n",
       "                                                              auc_sd  \\\n",
       "sampler    model parameter                 parameter_value             \n",
       "ADASYN     LR    classifier__C             1                0.034645   \n",
       "                 sampler__n_neighbors      5                0.033809   \n",
       "SMOTE      LR    classifier__C             1                0.032197   \n",
       "                 sampler__k_neighbors      5                0.036823   \n",
       "cGAN       LR    classifier__C             1                0.082427   \n",
       "                 sampler__critic_layers    [20]             0.035972   \n",
       "                 sampler__generator_layers [20]             0.084654   \n",
       "                 sampler__n_iter           1000             0.050765   \n",
       "unbalanced LR    classifier__C             1                0.027994   \n",
       "\n",
       "                                                             lift0.1  \\\n",
       "sampler    model parameter                 parameter_value             \n",
       "ADASYN     LR    classifier__C             1                1.068297   \n",
       "                 sampler__n_neighbors      5                1.061886   \n",
       "SMOTE      LR    classifier__C             1                1.064023   \n",
       "                 sampler__k_neighbors      5                1.066160   \n",
       "cGAN       LR    classifier__C             1                1.019196   \n",
       "                 sampler__critic_layers    [20]             0.991504   \n",
       "                 sampler__generator_layers [20]             0.974537   \n",
       "                 sampler__n_iter           1000             1.030048   \n",
       "unbalanced LR    classifier__C             1                1.057617   \n",
       "\n",
       "                                                            lift0.1_sd  \n",
       "sampler    model parameter                 parameter_value              \n",
       "ADASYN     LR    classifier__C             1                  0.024579  \n",
       "                 sampler__n_neighbors      5                  0.026447  \n",
       "SMOTE      LR    classifier__C             1                  0.020316  \n",
       "                 sampler__k_neighbors      5                  0.021355  \n",
       "cGAN       LR    classifier__C             1                  0.037761  \n",
       "                 sampler__critic_layers    [20]               0.061659  \n",
       "                 sampler__generator_layers [20]               0.052733  \n",
       "                 sampler__n_iter           1000               0.043520  \n",
       "unbalanced LR    classifier__C             1                  0.031181  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_scores.groupby(['sampler','model','parameter','parameter_value']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
      "       error_score='raise-deprecating',\n",
      "       estimator=Pipeline(memory='./.cachedir',\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('sampler', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', svm_estimator='deprecated')), ('classifier', LogisticRegress...ty='l2', random_state=None, solver='liblinear',\n",
      "          tol=0.0001, verbose=0, warm_start=False))]),\n",
      "       fit_params=None, iid=False, n_jobs=3,\n",
      "       param_grid={'sampler__k_neighbors': [5, 10, 20], 'classifier__C': [1]},\n",
      "       pre_dispatch='2*n_jobs', refit='auc', return_train_score=True,\n",
      "       scoring={'auc': make_scorer(roc_auc_score, needs_proba=True), 'TDLift': make_scorer(perc_lift_score, needs_proba=True, percentile=0.1)},\n",
      "       verbose=0)\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
      "       error_score='raise-deprecating',\n",
      "       estimator=Pipeline(memory='./.cachedir',\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('sampler', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', svm_estimator='deprecated')), ('classifier', LogisticRegress...ty='l2', random_state=None, solver='liblinear',\n",
      "          tol=0.0001, verbose=0, warm_start=False))]),\n",
      "       fit_params=None, iid=False, n_jobs=3,\n",
      "       param_grid={'sampler__k_neighbors': [5, 10, 20], 'classifier__C': [1]},\n",
      "       pre_dispatch='2*n_jobs', refit='auc', return_train_score=True,\n",
      "       scoring={'auc': make_scorer(roc_auc_score, needs_proba=True), 'TDLift': make_scorer(perc_lift_score, needs_proba=True, percentile=0.1)},\n",
      "       verbose=0)\n"
     ]
    }
   ],
   "source": [
    "for i in score_outer['SMOTE'][\"LR\"]['estimator']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
