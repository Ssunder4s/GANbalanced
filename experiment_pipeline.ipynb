{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n",
      "env: NUMEXPR_NUM_THREADS=1\n",
      "env: OMP_NUM_THREADS=1\n",
      "env: OPENBLAS_NUM_THREADS=1\n",
      "env: VECLIB_MAXIMUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_NUM_THREADS=1\n",
    "%env NUMEXPR_NUM_THREADS=1\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env OPENBLAS_NUM_THREADS=1\n",
    "%env VECLIB_MAXIMUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from lift.perc_lift_score import perc_lift_score\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Samplers\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from wgan.imblearn import GANbalancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X,y = make_classification(n_samples=4000, n_features=20, weights=[0.95,0.05], \n",
    "                          n_informative=20, n_redundant=0, n_clusters_per_class=5)\n",
    "\n",
    "# from wgan.data import load_DMC10\n",
    "# X, _, y, _, idx_cont, idx_cat, cat_dict = load_DMC10(\"/Users/hauptjoh/Data/DMC10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment.experiment_config import experiment_config\n",
    "scorers, models, samplers = experiment_config(X, idx_cont=None, idx_cat=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cont=None\n",
    "idx_cat = None\n",
    "\n",
    "### Samplers\n",
    "scorers = {'auc':make_scorer(roc_auc_score, needs_proba=True),\n",
    "          'TDLift':make_scorer(perc_lift_score, needs_proba=True, percentile=0.1)}\n",
    "\n",
    "### Models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear'), {\n",
    "    \"C\": [10]\n",
    "}))\n",
    "# models.append(('RF', RandomForestClassifier(), {\n",
    "#     \"n_estimators\":[100],\n",
    "#     \"max_features\":[\"sqrt\"],\n",
    "#     \"min_samples_leaf\":[20]\n",
    "# }))\n",
    "\n",
    "### Samplers\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from wgan.imblearn import GANbalancer\n",
    "\n",
    "samplers = []\n",
    "\n",
    "# GAN\n",
    "if idx_cont is None:\n",
    "    idx_cont = list(range(X.shape[1]))\n",
    "\n",
    "categorical = None\n",
    "if idx_cat is not None:\n",
    "    categorical = [(i,\n",
    "                    np.max(X[:,i])+1,\n",
    "                    int(min(15., np.ceil(np.max((X[:,i])+1)/2)))\n",
    "                   )\n",
    "                    for i in idx_cat]\n",
    "\n",
    "samplers.append(('cGAN', GANbalancer(\n",
    "        idx_cont=idx_cont, categorical=categorical, batch_size = 128, critic_iterations=1\n",
    "), {\n",
    "    'generator_input'  : [40],\n",
    "    'generator_layers' : [[100]],\n",
    "    'critic_layers'    : [[100]],\n",
    "    'n_iter'           : [40000,100000,1000000]\n",
    "}))\n",
    "\n",
    "# baseline\n",
    "samplers.append(('unbalanced', None, {}))\n",
    "\n",
    "# SMOTE\n",
    "samplers.append(('SMOTE', SMOTE(), {\n",
    "    'k_neighbors':[5,10]\n",
    "}))\n",
    "\n",
    "# ADASYN\n",
    "samplers.append(('ADASYN', ADASYN(), {\n",
    "    'n_neighbors':[5,10]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  15 | elapsed: 13.7min remaining: 12.0min\n",
      "[Parallel(n_jobs=20)]: Done  15 out of  15 | elapsed: 149.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  15 | elapsed: 13.9min remaining: 12.1min\n",
      "[Parallel(n_jobs=20)]: Done  15 out of  15 | elapsed: 122.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  15 | elapsed:  9.2min remaining:  8.0min\n",
      "[Parallel(n_jobs=20)]: Done  15 out of  15 | elapsed: 113.1min finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 501.6min finished\n",
      "\n",
      " 25%|██▌       | 1/4 [8:21:37<25:04:52, 30097.45s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.5s finished\n",
      "\n",
      " 50%|█████     | 2/4 [8:21:38<11:42:17, 21068.67s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   4 out of  10 | elapsed:    0.9s remaining:    1.3s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   4 out of  10 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   4 out of  10 | elapsed:    1.1s remaining:    1.7s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.2s finished\n",
      "\n",
      " 75%|███████▌  | 3/4 [8:21:48<4:05:50, 14750.83s/it] \n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   4 out of  10 | elapsed:    1.3s remaining:    2.0s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   4 out of  10 | elapsed:    5.2s remaining:    7.8s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   4 out of  10 | elapsed:    6.1s remaining:    9.2s\n",
      "[Parallel(n_jobs=20)]: Done  10 out of  10 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.4s finished\n",
      "\n",
      "100%|██████████| 4/4 [8:22:09<00:00, 10332.00s/it]  \n"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "\n",
    "score_outer = {}\n",
    "\n",
    "for sampler_name, sampler, sampler_grid in tqdm(samplers):\n",
    "    \n",
    "    sampler_grid = {'sampler__'+key:item for key, item in sampler_grid.items()}\n",
    "    \n",
    "    score_inner = {}\n",
    "\n",
    "    for model_name, model, model_grid in tqdm(models):\n",
    "\n",
    "        pipeline = Pipeline(memory='./.cachedir', steps=[\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('sampler', sampler),\n",
    "            ('classifier', model)\n",
    "          ])\n",
    "        model_grid = {'classifier__'+key:item for key, item in model_grid.items()}\n",
    "        p_grid = {**sampler_grid, **model_grid}\n",
    "        \n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "            \n",
    "        clf = GridSearchCV(pipeline, param_grid= p_grid, cv=inner_cv, scoring=scorers, refit='auc', \n",
    "                           return_train_score=True, iid=False, n_jobs=20, pre_dispatch=40, verbose=1)\n",
    "\n",
    "        score_inner[model_name] = cross_validate(clf, X=X,y=y,cv=outer_cv , scoring=scorers, return_train_score=True,\n",
    "                                    return_estimator=True, verbose=1)\n",
    "    score_outer[sampler_name] = score_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc    auc_sd   lift0.1  lift0.1_sd model     sampler\n",
      "0  0.776272  0.040642  1.080369    0.024811    LR        cGAN\n",
      "1  0.814863  0.038656  1.090651    0.007022    LR  unbalanced\n",
      "2  0.821822  0.035713  1.095655    0.000054    LR       SMOTE\n",
      "3  0.821116  0.035804  1.090651    0.007022    LR      ADASYN\n"
     ]
    }
   ],
   "source": [
    "scores = pd.DataFrame([{\n",
    "  'sampler':sampler_name, 'model':model_name, \n",
    "    'auc':np.mean(model[\"test_auc\"]),  'auc_sd':np.std(model[\"test_auc\"]),\n",
    "    'lift0.1':np.mean(model[\"test_TDLift\"]),  'lift0.1_sd':np.std(model[\"test_TDLift\"]),\n",
    "} for sampler_name, sampler in score_outer.items()\n",
    "    for model_name, model in sampler.items()]\n",
    ")\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = {sampler_name:\n",
    "    {model_name:\n",
    "    # vstack result DataFrame for each outer fold\n",
    "        pd.concat([ \n",
    "            # Inner CV tuning results as DataFrame\n",
    "            pd.concat([pd.DataFrame(inner_cv.cv_results_['params']).astype(str), \n",
    "                       pd.DataFrame({\n",
    "                           'mean_test_auc':inner_cv.cv_results_['mean_test_auc'],\n",
    "                           'std_test_auc':inner_cv.cv_results_['std_test_auc'],\n",
    "                           'mean_test_TDLift':inner_cv.cv_results_['mean_test_TDLift'],\n",
    "                           'std_test_TDLift':inner_cv.cv_results_['std_test_TDLift']\n",
    "                       })\n",
    "                      ], sort=False, ignore_index=False, axis=1)\n",
    "            for inner_cv in model['estimator']]).groupby(list(model['estimator'][0].cv_results_['params'][0].keys())).mean().reset_index()\n",
    "            for model_name, model in sampler.items()}\n",
    "          for sampler_name, sampler in score_outer.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier__C</th>\n",
       "      <th>sampler__critic_layers</th>\n",
       "      <th>sampler__generator_input</th>\n",
       "      <th>sampler__generator_layers</th>\n",
       "      <th>sampler__n_iter</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>mean_test_TDLift</th>\n",
       "      <th>std_test_TDLift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[100]</td>\n",
       "      <td>40</td>\n",
       "      <td>[100]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.780123</td>\n",
       "      <td>0.040656</td>\n",
       "      <td>1.087537</td>\n",
       "      <td>0.029349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>[100]</td>\n",
       "      <td>40</td>\n",
       "      <td>[100]</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.779761</td>\n",
       "      <td>0.037585</td>\n",
       "      <td>1.077583</td>\n",
       "      <td>0.028426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>[100]</td>\n",
       "      <td>40</td>\n",
       "      <td>[100]</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.777282</td>\n",
       "      <td>0.047214</td>\n",
       "      <td>1.090175</td>\n",
       "      <td>0.023121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier__C sampler__critic_layers sampler__generator_input  \\\n",
       "0            10                  [100]                       40   \n",
       "1            10                  [100]                       40   \n",
       "2            10                  [100]                       40   \n",
       "\n",
       "  sampler__generator_layers sampler__n_iter  mean_test_auc  std_test_auc  \\\n",
       "0                     [100]          100000       0.780123      0.040656   \n",
       "1                     [100]         1000000       0.779761      0.037585   \n",
       "2                     [100]           40000       0.777282      0.047214   \n",
       "\n",
       "   mean_test_TDLift  std_test_TDLift  \n",
       "0          1.087537         0.029349  \n",
       "1          1.077583         0.028426  \n",
       "2          1.090175         0.023121  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_results[\"cGAN\"][\"LR\"].sort_values([\"sampler__n_iter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-82c859e09251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'auc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'auc_sd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"std_test_auc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m'lift0.1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_test_TDLift\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'lift0.1_sd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"std_test_TDLift\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m }   for sampler_name, sampler in score_outer.items()\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-82c859e09251>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "parameter_scores =  pd.DataFrame([{\n",
    "  'sampler':sampler_name, 'model':model_name,\n",
    "    'parameter':param_name,\n",
    "    'parameter_value':str(param_value),\n",
    "    'auc':cv.cv_results_['mean_test_auc'][i],  'auc_sd':cv.cv_results_[\"std_test_auc\"][i],\n",
    "    'lift0.1':cv.cv_results_[\"mean_test_TDLift\"][i],  'lift0.1_sd':cv.cv_results_[\"std_test_TDLift\"][i]\n",
    "}   for sampler_name, sampler in score_outer.items()\n",
    "    for model_name, model in sampler.items()\n",
    "    for cv in model['estimator']\n",
    "    for i, (param_name, param_value) in enumerate(cv.cv_results_['params'][0].items())\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_scores.groupby(['sampler','model','parameter','parameter_value']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
