{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Evaluation functions\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from lift.perc_lift_score import perc_lift_score\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sys.path.append(\"/Users/hauptjoh/Projects/utils/imbalanced-learn/\")\n",
    "#sys.path.append(\"/home/RDC/hauptjoh.hub/GANbalanced\")\n",
    "# Samplers\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearnNC.under_sampling import TomekLinksNC\n",
    "\n",
    "from wgan.imblearn import GANbalancer\n",
    "import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs=3\n",
    "\n",
    "data_path = Path(\"~/Data/COIL00\")\n",
    "X, y = data_loader.load_coil00(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize index lists\n",
    "idx_cont = None\n",
    "idx_cat  = None\n",
    "\n",
    "if idx_cat is None:\n",
    "    idx_cat = list(np.where(X.dtypes == 'category')[0])\n",
    "    idx_cat = [int(x) for x in idx_cat]\n",
    "\n",
    "if idx_cont is None:\n",
    "    idx_cont = [x for x in range(X.shape[1]) if x not in idx_cat]\n",
    "    idx_cont = [int(x) for x in idx_cont]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding tuples\n",
    "categorical = None\n",
    "if idx_cat is not None:\n",
    "    categorical = [(i,\n",
    "                    len(X.iloc[:,i].cat.categories),\n",
    "                    int(min(15., np.ceil(0.5*len(X.iloc[:,i].cat.categories))))\n",
    "                   )\n",
    "                    for i in idx_cat]\n",
    "\n",
    "# Make sure categorical variables are encoded from 0\n",
    "if np.any([idx>min(idx_cat) for idx in idx_cont]):\n",
    "    raise ValueError(\"Variables need to be ordered [cont, cat]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.to_numpy(dtype=np.float32)\n",
    "y=y.to_numpy(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:   28.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:   27.7s finished\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.6min finished\n",
      "\n",
      "100%|██████████| 1/1 [01:35<00:00, 95.82s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [01:35<03:11, 95.83s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.6s finished\n",
      "\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.62s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:42<01:09, 69.07s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:   13.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 out of   2 | elapsed:   15.7s finished\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.1min finished\n",
      "\n",
      "100%|██████████| 1/1 [01:05<00:00, 65.57s/it]\u001b[A\n",
      "100%|██████████| 3/3 [02:48<00:00, 68.02s/it]\n"
     ]
    }
   ],
   "source": [
    "### Scorer\n",
    "scorers = {'auc':make_scorer(roc_auc_score, needs_proba=True),\n",
    "          'TDLift':make_scorer(perc_lift_score, needs_proba=True, percentile=0.1)}\n",
    "\n",
    "# Load specific experiment configuration\n",
    "config = {\n",
    " \"models\": {\n",
    "     \"LR\":{\n",
    "         \"C\": [10]\n",
    "   }\n",
    " },\n",
    " \"samplers\": {\n",
    "    \"cGAN\":{\n",
    "        \"generator_input\": [20],\n",
    "        \"generator_layers\": [[20]],\n",
    "        \"critic_layers\": [[20]],\n",
    "        \"n_iter\": [100],\n",
    "        \"critic_iterations\": [2]\n",
    "   },\n",
    "    \"unbalanced\":{},\n",
    "    \"SMOTE\":{\n",
    "        \"k_neighbors\": [3]\n",
    "   }\n",
    " }\n",
    "}\n",
    "\n",
    "\n",
    "### Models\n",
    "models = []\n",
    "model_fun = {\"LR\":LogisticRegression(solver='liblinear'),\n",
    "          \"RF\":RandomForestClassifier(min_samples_leaf=20)\n",
    "          }\n",
    "\n",
    "for model_name, model_params in config[\"models\"].items():\n",
    "    models.append((model_name, model_fun[model_name], model_params))\n",
    "\n",
    "### Samplers\n",
    "samplers = []\n",
    "sampler_fun = {\"cGAN\":GANbalancer(\\\n",
    "                         idx_cont=idx_cont, categorical=categorical,\n",
    "                         batch_size = 128, auxiliary=True),\n",
    "                \"unbalanced\":None,\n",
    "                \"SMOTE\":SMOTENC(categorical_features=idx_cat)\n",
    "}\n",
    "\n",
    "# Cleaner\n",
    "cleaner = TomekLinksNC(categorical_features=idx_cat, sampling_strategy='auto')\n",
    "\n",
    "for sampler_name, sampler_params in config[\"samplers\"].items():\n",
    "    samplers.append((sampler_name, sampler_fun[sampler_name], sampler_params))\n",
    "\n",
    "\n",
    "### Pipeline construction\n",
    "\n",
    "preproc_sampler = ColumnTransformer([\n",
    "    ('scaler', MinMaxScaler(), idx_cont),\n",
    "    ('pass',   'passthrough',  idx_cat)\n",
    "])\n",
    "\n",
    "preproc_clf = ColumnTransformer([\n",
    "    ('pass', 'passthrough', idx_cont),\n",
    "    ('ohe',   OneHotEncoder(categories='auto', handle_unknown='ignore'),  idx_cat)\n",
    "])\n",
    "\n",
    "\n",
    "seed = 123\n",
    "\n",
    "score_outer = {}\n",
    "\n",
    "for sampler_name, sampler, sampler_grid in tqdm(samplers):\n",
    "\n",
    "    sampler_grid = {'sampler__'+key:item for key, item in sampler_grid.items()}\n",
    "\n",
    "    score_inner = {}\n",
    "\n",
    "    for model_name, model, model_grid in tqdm(models):\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preproc_sampler', preproc_sampler),\n",
    "            ('sampler', sampler),\n",
    "            ('Cleaning', cleaner),\n",
    "            ('preproc_clf', preproc_clf),\n",
    "            ('classifier', model)\n",
    "          ])\n",
    "\n",
    "        model_grid = {'classifier__'+key:item for key, item in model_grid.items()}\n",
    "        p_grid = {**sampler_grid, **model_grid}\n",
    "\n",
    "        inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "        outer_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "\n",
    "        clf = GridSearchCV(pipeline, param_grid= p_grid, cv=inner_cv, scoring=scorers, refit='auc',\n",
    "                           return_train_score=True, iid=False,\n",
    "                           n_jobs=n_jobs, pre_dispatch=n_jobs*2, verbose=1)\n",
    "\n",
    "        score_inner[model_name] = cross_validate(clf, X=X,y=y,cv=outer_cv , scoring=scorers, return_train_score=True,\n",
    "                                    return_estimator=True, verbose=1, error_score='raise')\n",
    "    score_outer[sampler_name] = score_inner\n",
    "\n",
    "\n",
    "scores = pd.DataFrame([{\n",
    "  'sampler':sampler_name, 'model':model_name,\n",
    "    'auc':np.mean(model[\"test_auc\"]),  'auc_sd':np.std(model[\"test_auc\"]),\n",
    "    'lift0.1':np.mean(model[\"test_TDLift\"]),  'lift0.1_sd':np.std(model[\"test_TDLift\"]),\n",
    "} for sampler_name, sampler in score_outer.items()\n",
    "    for model_name, model in sampler.items()]\n",
    ")\n",
    "\n",
    "\n",
    "tuning_results = {sampler_name:\n",
    "    {model_name:\n",
    "    # vstack result DataFrame for each outer fold\n",
    "        pd.concat([\n",
    "            # Inner CV tuning results as DataFrame\n",
    "            pd.concat([pd.DataFrame(inner_cv.cv_results_['params']).astype(str),\n",
    "                       pd.DataFrame({\n",
    "                           'mean_test_auc':inner_cv.cv_results_['mean_test_auc'],\n",
    "                           'std_test_auc':inner_cv.cv_results_['std_test_auc'],\n",
    "                           'mean_test_TDLift':inner_cv.cv_results_['mean_test_TDLift'],\n",
    "                           'std_test_TDLift':inner_cv.cv_results_['std_test_TDLift']\n",
    "                       })\n",
    "                      ], sort=False, ignore_index=False, axis=1)\n",
    "            for inner_cv in model['estimator']]).groupby(list(model['estimator'][0].cv_results_['params'][0].keys())).mean().reset_index()\n",
    "            for model_name, model in sampler.items()}\n",
    "          for sampler_name, sampler in score_outer.items()}\n",
    "\n",
    "### Collect results\n",
    "scores = pd.DataFrame([{\n",
    "      'sampler':sampler_name, 'model':model_name,\n",
    "        'auc':np.mean(model[\"test_auc\"]),  'auc_sd':np.std(model[\"test_auc\"]),\n",
    "        'lift0.1':np.mean(model[\"test_TDLift\"]),  'lift0.1_sd':np.std(model[\"test_TDLift\"]),\n",
    "    } for sampler_name, sampler in score_outer.items()\n",
    "        for model_name, model in sampler.items()]\n",
    "    )\n",
    "\n",
    "tuning_results = {sampler_name:\n",
    "    {model_name:\n",
    "    # vstack result DataFrame for each outer fold\n",
    "        pd.concat([\n",
    "            # Inner CV tuning results as DataFrame\n",
    "            pd.concat([pd.DataFrame(inner_cv.cv_results_['params']).astype(str),\n",
    "                       pd.DataFrame({\n",
    "                           'mean_test_auc':inner_cv.cv_results_['mean_test_auc'],\n",
    "                           'std_test_auc':inner_cv.cv_results_['std_test_auc'],\n",
    "                           'mean_test_TDLift':inner_cv.cv_results_['mean_test_TDLift'],\n",
    "                           'std_test_TDLift':inner_cv.cv_results_['std_test_TDLift']\n",
    "                       })\n",
    "                      ], sort=False, ignore_index=False, axis=1)\n",
    "            for inner_cv in model['estimator']]).groupby(list(model['estimator'][0].cv_results_['params'][0].keys())).mean().reset_index()\n",
    "            for model_name, model in sampler.items()}\n",
    "          for sampler_name, sampler in score_outer.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
