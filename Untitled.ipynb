{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8002,  0.3854,  0.2316, -0.3850],\n",
       "        [-1.2222,  1.2016, -0.7167, -0.0084],\n",
       "        [ 0.2091,  1.4932,  0.4753,  0.1316],\n",
       "        [-0.2015,  0.4398,  1.5051, -0.3116],\n",
       "        [-1.4080, -0.1282, -0.7759,  1.6480],\n",
       "        [ 1.1012, -1.8416,  0.0751, -1.2648],\n",
       "        [-1.1180,  0.4721, -0.0142, -0.9452],\n",
       "        [ 2.0144,  0.9212, -0.0773, -0.5673],\n",
       "        [-0.5059,  0.8515, -0.4677, -1.7405],\n",
       "        [-0.5505, -0.1025,  1.0220,  0.8360]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2739,  0.2993, -0.0621, -1.5111],\n",
       "        [-1.1382,  1.5253, -0.5827,  0.1956],\n",
       "        [-0.6769,  1.6838, -0.1875, -0.8194],\n",
       "        [-0.7751,  0.1134,  1.5893, -0.9276],\n",
       "        [-1.0886,  0.0331, -0.5346,  1.5900],\n",
       "        [ 1.3787, -1.1831,  0.4854, -0.6810],\n",
       "        [-1.0923,  1.3311,  0.5900, -0.8288],\n",
       "        [ 1.4559,  0.3519, -0.6565, -1.1513],\n",
       "        [-0.0439,  1.4367, -0.0022, -1.3906],\n",
       "        [-1.3089, -0.6204,  1.1075,  0.8218]], grad_fn=<AddcmulBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Learnable Parameters\n",
    "m = nn.LayerNorm(input.size()[1:])\n",
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.state_dict()['bias'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2739,  0.2993, -0.0621, -1.5111],\n",
       "        [-1.1382,  1.5253, -0.5827,  0.1956],\n",
       "        [-0.6769,  1.6838, -0.1875, -0.8194],\n",
       "        [-0.7751,  0.1134,  1.5893, -0.9276],\n",
       "        [-1.0886,  0.0331, -0.5346,  1.5900],\n",
       "        [ 1.3787, -1.1831,  0.4854, -0.6810],\n",
       "        [-1.0923,  1.3311,  0.5900, -0.8288],\n",
       "        [ 1.4559,  0.3519, -0.6565, -1.1513],\n",
       "        [-0.0439,  1.4367, -0.0022, -1.3906],\n",
       "        [-1.3089, -0.6204,  1.1075,  0.8218]], grad_fn=<AddcmulBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize over last two dimensions\n",
    "m = nn.LayerNorm([4])\n",
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([1., 1., 1., 1.])),\n",
       "             ('bias', tensor([0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2739,  0.2993, -0.0621, -1.5111],\n",
       "        [-1.1382,  1.5253, -0.5827,  0.1956],\n",
       "        [-0.6769,  1.6838, -0.1875, -0.8194],\n",
       "        [-0.7751,  0.1134,  1.5893, -0.9276],\n",
       "        [-1.0886,  0.0331, -0.5346,  1.5900],\n",
       "        [ 1.3787, -1.1831,  0.4854, -0.6810],\n",
       "        [-1.0923,  1.3311,  0.5900, -0.8288],\n",
       "        [ 1.4559,  0.3519, -0.6565, -1.1513],\n",
       "        [-0.0439,  1.4367, -0.0022, -1.3906],\n",
       "        [-1.3089, -0.6204,  1.1075,  0.8218]], grad_fn=<AddcmulBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize over last dimension of size 10\n",
    "m = nn.LayerNorm(4)\n",
    "# Activating the module\n",
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
