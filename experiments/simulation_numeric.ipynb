{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale, scale, MinMaxScaler\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan.models_cont import Generator, Discriminator\n",
    "from wgan.training import WGAN\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from imbalanced_sampler.sampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correlation_matrix(no_var):\n",
    "    corr = np.zeros([no_var,no_var])\n",
    "    corr_temp = np.random.uniform(-1,1,size=[(no_var-1)*2])\n",
    "    corr[np.triu_indices(no_var, 1)] = corr_temp\n",
    "    corr + corr.T + np.eye(no_var)\n",
    "    return corr\n",
    "\n",
    "\n",
    "def create_continuous_data(N, pos_ratio=0, noise_ratio=0, no_var=10, cov=None, random_state=None):\n",
    "    if random_state is not None: np.random.seed(random_state)\n",
    "    # Group indicator\n",
    "    #group = sp.binom.rvs(p=0.25, n=1, size=N    \n",
    "    N_neg = int(N*(1-pos_ratio))\n",
    "    N_pos = N-N_neg\n",
    "    y = np.concatenate([np.zeros(N_neg), np.ones(N_pos)])\n",
    "    \n",
    "    mean = np.random.uniform(size=no_var)\n",
    "    mean0 = np.random.normal(loc=mean,scale=0.5)\n",
    "    mean1 = np.random.normal(loc=mean,scale=0.5)\n",
    "    \n",
    "    if cov is None: \n",
    "        cov0 = sp.invwishart.rvs(df=no_var*2, scale=np.eye(no_var))\n",
    "        cov1 = sp.invwishart.rvs(df=no_var*2, scale=np.eye(no_var))\n",
    "\n",
    "    # Noise are variables with same distribution in majority and minority class\n",
    "    if noise_ratio != 0:  \n",
    "        no_noise = int(noise_ratio*no_var)\n",
    "        no_var = no_var - no_noise\n",
    "        X_noise = sp.multivariate_normal.rvs(mean=mean0[no_var:], cov=cov0[no_var:,no_var:], size=N).reshape([N,-1])\n",
    "\n",
    "    X1 = sp.multivariate_normal.rvs(mean=mean1[0:no_var], cov= cov1[:no_var,:no_var], size=N_pos)\n",
    "    X0 = sp.multivariate_normal.rvs(mean=mean0[0:no_var], cov= cov0[:no_var,:no_var], size=N_neg)\n",
    "    X = np.vstack([X0,X1])\n",
    "    X = np.hstack([X, X_noise])\n",
    "    \n",
    "    return {\"X\":X, \"y\":y,\"mean0\":mean0,\"mean1\":mean1, \"cov0\":cov0, \"cov1\":cov1}\n",
    "\n",
    "def create_dataset(n_samples=1000, n_features=2, n_classes=3, weights=(0.01, 0.01, 0.98),\n",
    "                   class_sep=0.8, n_clusters=1, random_state=0):\n",
    "    return make_classification(n_samples=n_samples,\n",
    "                               n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                               n_classes=n_classes, n_features = n_features,\n",
    "                               n_clusters_per_class=n_clusters,\n",
    "                               weights=list(weights),\n",
    "                               class_sep=class_sep, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifical Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Characterizes a Dataset for PyTorch\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        data: pandas data frame\n",
    "          The data frame object for the input data. It must\n",
    "          contain all the continuous, categorical and the\n",
    "          output columns to be used.\n",
    "\n",
    "        cat_cols: List of strings\n",
    "          The names of the categorical columns in the data.\n",
    "          These columns will be passed through the embedding\n",
    "          layers in the model. These columns must be\n",
    "          label encoded beforehand.\n",
    "\n",
    "        output_col: string\n",
    "          The name of the output variable column in the data\n",
    "          provided.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = X.shape[0]\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the total number of samples.\n",
    "        \"\"\"\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        return [self.X[idx], self.y[idx],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modus = 'full' #'full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_vars = 2\n",
    "N= 10000\n",
    "\n",
    "#data = create_continuous_data(N, pos_ratio=0.1, noise_ratio=0.5, no_var=no_vars, random_state=123) #, cov=np.eye(no_vars)\n",
    "\n",
    "X_full,y = make_classification(n_samples=N, weights=[0.9,0.1], n_clusters_per_class=1,\n",
    "                              n_features=no_vars, \n",
    "                              n_informative=no_vars, \n",
    "                              n_redundant=0, n_repeated=0,\n",
    "                             random_state=123)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y, \n",
    "                                                    stratify=y, test_size=0.5, random_state=123)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train_majority = X_train[y_train==0,:]\n",
    "X_train_minority = X_train[y_train==1,:]\n",
    "\n",
    "y_train_bin = y_train[:]\n",
    "y_temp = np.zeros([len(y_train),2])\n",
    "y_temp[y_train==0,0] = 1\n",
    "y_temp[y_train==1,1] = 1\n",
    "y_train = y_temp\n",
    "\n",
    "#mean_minority = np.mean(X_minority, axis=0)\n",
    "#sd_minority = np.std(X_minority, axis=0)\n",
    "#X_minority = (X_minority-mean_minority)/sd_minority\n",
    "\n",
    "if modus == 'minority':\n",
    "    dataset = TabularDataset(X_train_minority, y_train[np.argmax(y_train, axis=1),:])\n",
    "elif modus == 'full':\n",
    "    dataset = TabularDataset(X_train, y_train)\n",
    "else:\n",
    "    stop(\"Check modus. Must be one of ['minority, 'full]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35726075 0.3421497 ]\n",
      "[0.14262311 0.11910413]\n",
      "[0.63989079 0.66437871]\n",
      "[0.10413336 0.10005858]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_train_minority, axis=0))\n",
    "print(np.std(X_train_minority, axis=0))\n",
    "print(np.mean(X_train_majority, axis=0))\n",
    "print(np.std(X_train_majority, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_vars = 12\n",
    "# X, y = create_dataset(n_samples=200000, n_classes=2, weights=(0.05,0.95), n_features=no_vars,\n",
    "#                      n_clusters=1, class_sep=0.8, random_state=123)\n",
    "\n",
    "# X = minmax_scale(X)\n",
    "# X_majority = X[y==0,:]\n",
    "# X_minority = X[y==1,:]\n",
    "\n",
    "# dataset = TabularDataset(X_minority, y[y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ImbalancedDatasetSampler(labels = y_train_bin, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "# Balanced sampling through inverse propensiImbalancedDatasetSampler(labels = list(y_train), num_samples=batch_size)ty\n",
    "#data_loader = DataLoader(dataset, batch_size = batch_size, \n",
    "#                     sampler = sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (lin_layers): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Discriminator(\n",
      "  (lin_layers): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(latent_dim=10, lin_layer_sizes=[128,256], output_dim=no_vars, aux_dim=0)\n",
    "\n",
    "discriminator = Discriminator(input_size=no_vars, lin_layer_sizes=[128,128], aux_input_size=0)\n",
    "\n",
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizers\n",
    "lr_G = 5e-5\n",
    "lr_D = 5e-5\n",
    "betas = (.9, .99)\n",
    "G_optimizer = optim.Adam(generator.parameters(), lr=lr_G, betas=betas)\n",
    "D_optimizer = optim.Adam(discriminator.parameters(), lr=lr_D, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = WGAN(generator, discriminator, G_optimizer, D_optimizer, print_every=1000,\n",
    "                  use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.gp_weight = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Iteration 1\n",
      "D: -0.014640197157859802\n",
      "GP: 8.166168212890625\n",
      "Gradient norm: 0.09640739113092422\n",
      "\n",
      "Epoch 2\n",
      "Iteration 1\n",
      "D: -0.03755280375480652\n",
      "GP: 3.8522980213165283\n",
      "Gradient norm: 0.3799523711204529\n",
      "\n",
      "Epoch 3\n",
      "Iteration 1\n",
      "D: -0.08430594205856323\n",
      "GP: 1.4303369522094727\n",
      "Gradient norm: 0.6253386735916138\n",
      "G: -0.5480396747589111\n",
      "Distance: 0.08430594205856323\n",
      "\n",
      "Epoch 4\n",
      "Iteration 1\n",
      "D: -0.09473645687103271\n",
      "GP: 0.21663829684257507\n",
      "Gradient norm: 0.8623771667480469\n",
      "G: -0.8660480976104736\n",
      "Distance: 0.09473645687103271\n",
      "\n",
      "Epoch 5\n",
      "Iteration 1\n",
      "D: -0.15546107292175293\n",
      "GP: 0.006872779689729214\n",
      "Gradient norm: 0.9974378347396851\n",
      "G: -1.0165677070617676\n",
      "Distance: 0.15546107292175293\n",
      "\n",
      "Epoch 6\n",
      "Iteration 1\n",
      "D: -0.1536095142364502\n",
      "GP: 0.00587007962167263\n",
      "Gradient norm: 1.0061150789260864\n",
      "G: -1.0165677070617676\n",
      "Distance: 0.1536095142364502\n",
      "\n",
      "Epoch 7\n",
      "Iteration 1\n",
      "D: -0.1534423828125\n",
      "GP: 0.0050646415911614895\n",
      "Gradient norm: 1.0079965591430664\n",
      "G: -1.0130975246429443\n",
      "Distance: 0.1534423828125\n",
      "\n",
      "Epoch 8\n",
      "Iteration 1\n",
      "D: -0.1486508846282959\n",
      "GP: 0.005559563636779785\n",
      "Gradient norm: 1.001961350440979\n",
      "G: -1.0069897174835205\n",
      "Distance: 0.1486508846282959\n",
      "\n",
      "Epoch 9\n",
      "Iteration 1\n",
      "D: -0.10569000244140625\n",
      "GP: 0.007734390906989574\n",
      "Gradient norm: 0.9980465769767761\n",
      "G: -1.0098557472229004\n",
      "Distance: 0.10569000244140625\n",
      "\n",
      "Epoch 10\n",
      "Iteration 1\n",
      "D: -0.18288755416870117\n",
      "GP: 0.004171984735876322\n",
      "Gradient norm: 1.006897211074829\n",
      "G: -1.0152769088745117\n",
      "Distance: 0.18288755416870117\n",
      "\n",
      "Epoch 11\n",
      "Iteration 1\n",
      "D: -0.1669020652770996\n",
      "GP: 0.0029451248701661825\n",
      "Gradient norm: 1.0064337253570557\n",
      "G: -1.0152769088745117\n",
      "Distance: 0.1669020652770996\n",
      "\n",
      "Epoch 12\n",
      "Iteration 1\n",
      "D: -0.1798267364501953\n",
      "GP: 0.002466079778969288\n",
      "Gradient norm: 1.0069856643676758\n",
      "G: -1.0189580917358398\n",
      "Distance: 0.1798267364501953\n",
      "\n",
      "Epoch 13\n",
      "Iteration 1\n",
      "D: -0.13206863403320312\n",
      "GP: 0.0032721974421292543\n",
      "Gradient norm: 1.0060551166534424\n",
      "G: -1.0225061178207397\n",
      "Distance: 0.13206863403320312\n",
      "\n",
      "Epoch 14\n",
      "Iteration 1\n",
      "D: -0.1099252700805664\n",
      "GP: 0.001659660367295146\n",
      "Gradient norm: 1.0055088996887207\n",
      "G: -1.02310311794281\n",
      "Distance: 0.1099252700805664\n",
      "\n",
      "Epoch 15\n",
      "Iteration 1\n",
      "D: -0.10853314399719238\n",
      "GP: 0.0031489108223468065\n",
      "Gradient norm: 1.0037086009979248\n",
      "G: -1.0233452320098877\n",
      "Distance: 0.10853314399719238\n",
      "\n",
      "Epoch 16\n",
      "Iteration 1\n",
      "D: -0.1484907865524292\n",
      "GP: 0.0028517767786979675\n",
      "Gradient norm: 1.0105458498001099\n",
      "G: -1.0233452320098877\n",
      "Distance: 0.1484907865524292\n",
      "\n",
      "Epoch 17\n",
      "Iteration 1\n",
      "D: -0.14639854431152344\n",
      "GP: 0.003486969508230686\n",
      "Gradient norm: 1.0079278945922852\n",
      "G: -1.0272297859191895\n",
      "Distance: 0.14639854431152344\n",
      "\n",
      "Epoch 18\n",
      "Iteration 1\n",
      "D: -0.17260348796844482\n",
      "GP: 0.003272840054705739\n",
      "Gradient norm: 1.0074129104614258\n",
      "G: -1.0288398265838623\n",
      "Distance: 0.17260348796844482\n",
      "\n",
      "Epoch 19\n",
      "Iteration 1\n",
      "D: -0.13519954681396484\n",
      "GP: 0.007520959712564945\n",
      "Gradient norm: 1.006772756576538\n",
      "G: -1.034319281578064\n",
      "Distance: 0.13519954681396484\n",
      "\n",
      "Epoch 20\n",
      "Iteration 1\n",
      "D: -0.15461623668670654\n",
      "GP: 0.005182947963476181\n",
      "Gradient norm: 1.0081901550292969\n",
      "G: -1.0368764400482178\n",
      "Distance: 0.15461623668670654\n",
      "\n",
      "Epoch 21\n",
      "Iteration 1\n",
      "D: -0.14365005493164062\n",
      "GP: 0.00840325839817524\n",
      "Gradient norm: 1.0028358697891235\n",
      "G: -1.0368764400482178\n",
      "Distance: 0.14365005493164062\n",
      "\n",
      "Epoch 22\n",
      "Iteration 1\n",
      "D: -0.18403100967407227\n",
      "GP: 0.0032329587265849113\n",
      "Gradient norm: 1.0132898092269897\n",
      "G: -1.0347462892532349\n",
      "Distance: 0.18403100967407227\n",
      "\n",
      "Epoch 23\n",
      "Iteration 1\n",
      "D: -0.1695469617843628\n",
      "GP: 0.005012764595448971\n",
      "Gradient norm: 1.001150131225586\n",
      "G: -1.0302650928497314\n",
      "Distance: 0.1695469617843628\n",
      "\n",
      "Epoch 24\n",
      "Iteration 1\n",
      "D: -0.1557997465133667\n",
      "GP: 0.008409366011619568\n",
      "Gradient norm: 1.0073391199111938\n",
      "G: -1.0273480415344238\n",
      "Distance: 0.1557997465133667\n",
      "\n",
      "Epoch 25\n",
      "Iteration 1\n",
      "D: -0.16027820110321045\n",
      "GP: 0.00344298523850739\n",
      "Gradient norm: 1.0092848539352417\n",
      "G: -1.0273480415344238\n",
      "Distance: 0.16027820110321045\n",
      "\n",
      "Epoch 26\n",
      "Iteration 1\n",
      "D: -0.15383338928222656\n",
      "GP: 0.005809139460325241\n",
      "Gradient norm: 1.0047658681869507\n",
      "G: -1.0228196382522583\n",
      "Distance: 0.15383338928222656\n",
      "\n",
      "Epoch 27\n",
      "Iteration 1\n",
      "D: -0.1529597043991089\n",
      "GP: 0.008919582702219486\n",
      "Gradient norm: 1.0018686056137085\n",
      "G: -1.01748526096344\n",
      "Distance: 0.1529597043991089\n",
      "\n",
      "Epoch 28\n",
      "Iteration 1\n",
      "D: -0.1476360559463501\n",
      "GP: 0.005532009527087212\n",
      "Gradient norm: 1.0077394247055054\n",
      "G: -1.0202655792236328\n",
      "Distance: 0.1476360559463501\n",
      "\n",
      "Epoch 29\n",
      "Iteration 1\n",
      "D: -0.17444229125976562\n",
      "GP: 0.001885859528556466\n",
      "Gradient norm: 1.0074708461761475\n",
      "G: -1.0249855518341064\n",
      "Distance: 0.17444229125976562\n",
      "\n",
      "Epoch 30\n",
      "Iteration 1\n",
      "D: -0.13564002513885498\n",
      "GP: 0.00595729099586606\n",
      "Gradient norm: 1.0046528577804565\n",
      "G: -1.0249855518341064\n",
      "Distance: 0.13564002513885498\n",
      "\n",
      "Epoch 31\n",
      "Iteration 1\n",
      "D: -0.16174709796905518\n",
      "GP: 0.0036992167588323355\n",
      "Gradient norm: 1.0103330612182617\n",
      "G: -1.0295623540878296\n",
      "Distance: 0.16174709796905518\n",
      "\n",
      "Epoch 32\n",
      "Iteration 1\n",
      "D: -0.16523969173431396\n",
      "GP: 0.003378193359822035\n",
      "Gradient norm: 1.013791799545288\n",
      "G: -1.0292623043060303\n",
      "Distance: 0.16523969173431396\n",
      "\n",
      "Epoch 33\n",
      "Iteration 1\n",
      "D: -0.1378016471862793\n",
      "GP: 0.0089184008538723\n",
      "Gradient norm: 1.0005155801773071\n",
      "G: -1.0268242359161377\n",
      "Distance: 0.1378016471862793\n",
      "\n",
      "Epoch 34\n",
      "Iteration 1\n",
      "D: -0.1484771966934204\n",
      "GP: 0.004608573392033577\n",
      "Gradient norm: 1.0096490383148193\n",
      "G: -1.0403578281402588\n",
      "Distance: 0.1484771966934204\n",
      "\n",
      "Epoch 35\n",
      "Iteration 1\n",
      "D: -0.08862435817718506\n",
      "GP: 0.017330531030893326\n",
      "Gradient norm: 0.9986085891723633\n",
      "G: -1.0494916439056396\n",
      "Distance: 0.08862435817718506\n",
      "\n",
      "Epoch 36\n",
      "Iteration 1\n",
      "D: -0.11288034915924072\n",
      "GP: 0.004027226008474827\n",
      "Gradient norm: 1.0063273906707764\n",
      "G: -1.0532341003417969\n",
      "Distance: 0.11288034915924072\n",
      "\n",
      "Epoch 37\n",
      "Iteration 1\n",
      "D: -0.08378911018371582\n",
      "GP: 0.013505233451724052\n",
      "Gradient norm: 1.005599021911621\n",
      "G: -1.0781114101409912\n",
      "Distance: 0.08378911018371582\n",
      "\n",
      "Epoch 38\n",
      "Iteration 1\n",
      "D: -0.07445037364959717\n",
      "GP: 0.008951062336564064\n",
      "Gradient norm: 1.001546025276184\n",
      "G: -1.0926134586334229\n",
      "Distance: 0.07445037364959717\n",
      "\n",
      "Epoch 39\n",
      "Iteration 1\n",
      "D: -0.04293406009674072\n",
      "GP: 0.009217665530741215\n",
      "Gradient norm: 1.0010623931884766\n",
      "G: -1.096432089805603\n",
      "Distance: 0.04293406009674072\n",
      "\n",
      "Epoch 40\n",
      "Iteration 1\n",
      "D: -0.0518416166305542\n",
      "GP: 0.00680788978934288\n",
      "Gradient norm: 1.0031201839447021\n",
      "G: -1.1164275407791138\n",
      "Distance: 0.0518416166305542\n",
      "\n",
      "Epoch 41\n",
      "Iteration 1\n",
      "D: -0.014924883842468262\n",
      "GP: 0.011632189154624939\n",
      "Gradient norm: 1.0003094673156738\n",
      "G: -1.1591918468475342\n",
      "Distance: 0.014924883842468262\n",
      "\n",
      "Epoch 42\n",
      "Iteration 1\n",
      "D: 0.02277696132659912\n",
      "GP: 0.01752539351582527\n",
      "Gradient norm: 0.9941850900650024\n",
      "G: -1.1577736139297485\n",
      "Distance: -0.02277696132659912\n",
      "\n",
      "Epoch 43\n",
      "Iteration 1\n",
      "D: 0.03558075428009033\n",
      "GP: 0.009614150039851665\n",
      "Gradient norm: 1.0079807043075562\n",
      "G: -1.1805834770202637\n",
      "Distance: -0.03558075428009033\n",
      "\n",
      "Epoch 44\n",
      "Iteration 1\n",
      "D: 0.06453871726989746\n",
      "GP: 0.018954191356897354\n",
      "Gradient norm: 0.9945746064186096\n",
      "G: -1.174104928970337\n",
      "Distance: -0.06453871726989746\n",
      "\n",
      "Epoch 45\n",
      "Iteration 1\n",
      "D: 0.051325201988220215\n",
      "GP: 0.008746831677854061\n",
      "Gradient norm: 0.9934786558151245\n",
      "G: -1.1729347705841064\n",
      "Distance: -0.051325201988220215\n",
      "\n",
      "Epoch 46\n",
      "Iteration 1\n",
      "D: 0.09240663051605225\n",
      "GP: 0.029966002330183983\n",
      "Gradient norm: 0.9904342293739319\n",
      "G: -1.1866025924682617\n",
      "Distance: -0.09240663051605225\n",
      "\n",
      "Epoch 47\n",
      "Iteration 1\n",
      "D: 0.08635139465332031\n",
      "GP: 0.018306922167539597\n",
      "Gradient norm: 0.992063045501709\n",
      "G: -1.1576457023620605\n",
      "Distance: -0.08635139465332031\n",
      "\n",
      "Epoch 48\n",
      "Iteration 1\n",
      "D: 0.10597467422485352\n",
      "GP: 0.023797301575541496\n",
      "Gradient norm: 0.9889580607414246\n",
      "G: -1.1322762966156006\n",
      "Distance: -0.10597467422485352\n",
      "\n",
      "Epoch 49\n",
      "Iteration 1\n",
      "D: 0.0935356616973877\n",
      "GP: 0.027727019041776657\n",
      "Gradient norm: 0.985808789730072\n",
      "G: -1.092445731163025\n",
      "Distance: -0.0935356616973877\n",
      "\n",
      "Epoch 50\n",
      "Iteration 1\n",
      "D: 0.10610246658325195\n",
      "GP: 0.03067050501704216\n",
      "Gradient norm: 0.9784992933273315\n",
      "G: -1.01958167552948\n",
      "Distance: -0.10610246658325195\n",
      "\n",
      "Epoch 51\n",
      "Iteration 1\n",
      "D: 0.06735026836395264\n",
      "GP: 0.04629608988761902\n",
      "Gradient norm: 0.9818643927574158\n",
      "G: -0.9366748332977295\n",
      "Distance: -0.06735026836395264\n",
      "\n",
      "Epoch 52\n",
      "Iteration 1\n",
      "D: 0.038942813873291016\n",
      "GP: 0.047173015773296356\n",
      "Gradient norm: 0.9750513434410095\n",
      "G: -0.7197204828262329\n",
      "Distance: -0.038942813873291016\n",
      "\n",
      "Epoch 53\n",
      "Iteration 1\n",
      "D: -0.14588256180286407\n",
      "GP: 0.030288416892290115\n",
      "Gradient norm: 0.9985765218734741\n",
      "G: -0.12252393364906311\n",
      "Distance: 0.14588256180286407\n",
      "\n",
      "Epoch 54\n",
      "Iteration 1\n",
      "D: -0.24099640548229218\n",
      "GP: 0.03234776109457016\n",
      "Gradient norm: 1.0149860382080078\n",
      "G: 0.4244270622730255\n",
      "Distance: 0.24099640548229218\n",
      "\n",
      "Epoch 55\n",
      "Iteration 1\n",
      "D: -0.28038832545280457\n",
      "GP: 0.0329604335129261\n",
      "Gradient norm: 1.015142798423767\n",
      "G: 0.5750710964202881\n",
      "Distance: 0.28038832545280457\n",
      "\n",
      "Epoch 56\n",
      "Iteration 1\n",
      "D: -0.27217352390289307\n",
      "GP: 0.02171192318201065\n",
      "Gradient norm: 1.0140187740325928\n",
      "G: 0.6613853573799133\n",
      "Distance: 0.27217352390289307\n",
      "\n",
      "Epoch 57\n",
      "Iteration 1\n",
      "D: -0.2866191864013672\n",
      "GP: 0.017409266903996468\n",
      "Gradient norm: 1.0174884796142578\n",
      "G: 0.6878840327262878\n",
      "Distance: 0.2866191864013672\n",
      "\n",
      "Epoch 58\n",
      "Iteration 1\n",
      "D: -0.26352041959762573\n",
      "GP: 0.009148534387350082\n",
      "Gradient norm: 1.0078083276748657\n",
      "G: 0.7051450610160828\n",
      "Distance: 0.26352041959762573\n",
      "\n",
      "Epoch 59\n",
      "Iteration 1\n",
      "D: -0.22785568237304688\n",
      "GP: 0.017191234976053238\n",
      "Gradient norm: 1.0203455686569214\n",
      "G: 0.7202085256576538\n",
      "Distance: 0.22785568237304688\n",
      "\n",
      "Epoch 60\n",
      "Iteration 1\n",
      "D: -0.22006171941757202\n",
      "GP: 0.02412431128323078\n",
      "Gradient norm: 1.0218786001205444\n",
      "G: 0.7440325021743774\n",
      "Distance: 0.22006171941757202\n",
      "\n",
      "Epoch 61\n",
      "Iteration 1\n",
      "D: -0.17653918266296387\n",
      "GP: 0.013461355119943619\n",
      "Gradient norm: 1.0042206048965454\n",
      "G: 0.7165383696556091\n",
      "Distance: 0.17653918266296387\n",
      "\n",
      "Epoch 62\n",
      "Iteration 1\n",
      "D: -0.16248255968093872\n",
      "GP: 0.012741797603666782\n",
      "Gradient norm: 1.0116909742355347\n",
      "G: 0.7160133123397827\n",
      "Distance: 0.16248255968093872\n",
      "\n",
      "Epoch 63\n",
      "Iteration 1\n",
      "D: -0.09414166212081909\n",
      "GP: 0.008990218862891197\n",
      "Gradient norm: 0.9995710253715515\n",
      "G: 0.6864131093025208\n",
      "Distance: 0.09414166212081909\n",
      "\n",
      "Epoch 64\n",
      "Iteration 1\n",
      "D: -0.09982383251190186\n",
      "GP: 0.0026317124720662832\n",
      "Gradient norm: 1.0060055255889893\n",
      "G: 0.6695268750190735\n",
      "Distance: 0.09982383251190186\n",
      "\n",
      "Epoch 65\n",
      "Iteration 1\n",
      "D: -0.05796235799789429\n",
      "GP: 0.010824128985404968\n",
      "Gradient norm: 1.0003175735473633\n",
      "G: 0.6373623013496399\n",
      "Distance: 0.05796235799789429\n",
      "\n",
      "Epoch 66\n",
      "Iteration 1\n",
      "D: -0.02190643548965454\n",
      "GP: 0.01004632655531168\n",
      "Gradient norm: 1.0069968700408936\n",
      "G: 0.6266224980354309\n",
      "Distance: 0.02190643548965454\n",
      "\n",
      "Epoch 67\n",
      "Iteration 1\n",
      "D: -0.04446333646774292\n",
      "GP: 0.0022420966997742653\n",
      "Gradient norm: 1.0037691593170166\n",
      "G: 0.583899974822998\n",
      "Distance: 0.04446333646774292\n",
      "\n",
      "Epoch 68\n",
      "Iteration 1\n",
      "D: -0.05859184265136719\n",
      "GP: 0.010402536951005459\n",
      "Gradient norm: 1.002189040184021\n",
      "G: 0.5658528804779053\n",
      "Distance: 0.05859184265136719\n",
      "\n",
      "Epoch 69\n",
      "Iteration 1\n",
      "D: 0.010115742683410645\n",
      "GP: 0.021133288741111755\n",
      "Gradient norm: 0.9904533624649048\n",
      "G: 0.5177178978919983\n",
      "Distance: -0.010115742683410645\n",
      "\n",
      "Epoch 70\n",
      "Iteration 1\n",
      "D: 0.004096239805221558\n",
      "GP: 0.018036404624581337\n",
      "Gradient norm: 0.9918972253799438\n",
      "G: 0.45118647813796997\n",
      "Distance: -0.004096239805221558\n",
      "\n",
      "Epoch 71\n",
      "Iteration 1\n",
      "D: 0.014472663402557373\n",
      "GP: 0.01902412250638008\n",
      "Gradient norm: 0.9885298609733582\n",
      "G: 0.39724552631378174\n",
      "Distance: -0.014472663402557373\n",
      "\n",
      "Epoch 72\n",
      "Iteration 1\n",
      "D: 0.017806977033615112\n",
      "GP: 0.042602524161338806\n",
      "Gradient norm: 0.9860126972198486\n",
      "G: 0.3112998604774475\n",
      "Distance: -0.017806977033615112\n",
      "\n",
      "Epoch 73\n",
      "Iteration 1\n",
      "D: 0.0032512247562408447\n",
      "GP: 0.020425748080015182\n",
      "Gradient norm: 0.9843608736991882\n",
      "G: 0.18328920006752014\n",
      "Distance: -0.0032512247562408447\n",
      "\n",
      "Epoch 74\n",
      "Iteration 1\n",
      "D: -0.058691442012786865\n",
      "GP: 0.045839838683605194\n",
      "Gradient norm: 0.978411853313446\n",
      "G: -0.08529353141784668\n",
      "Distance: 0.058691442012786865\n",
      "\n",
      "Epoch 75\n",
      "Iteration 1\n",
      "D: -0.15779376029968262\n",
      "GP: 0.028808187693357468\n",
      "Gradient norm: 1.0141935348510742\n",
      "G: -0.34721866250038147\n",
      "Distance: 0.15779376029968262\n",
      "\n",
      "Epoch 76\n",
      "Iteration 1\n",
      "D: -0.12777042388916016\n",
      "GP: 0.051149189472198486\n",
      "Gradient norm: 1.0027281045913696\n",
      "G: -0.43527892231941223\n",
      "Distance: 0.12777042388916016\n",
      "\n",
      "Epoch 77\n",
      "Iteration 1\n",
      "D: -0.11636865139007568\n",
      "GP: 0.15114641189575195\n",
      "Gradient norm: 1.0129072666168213\n",
      "G: -0.5268010497093201\n",
      "Distance: 0.11636865139007568\n",
      "\n",
      "Epoch 78\n",
      "Iteration 1\n",
      "D: -0.10946476459503174\n",
      "GP: 0.10734149813652039\n",
      "Gradient norm: 0.9974876642227173\n",
      "G: -0.5963050723075867\n",
      "Distance: 0.10946476459503174\n",
      "\n",
      "Epoch 79\n",
      "Iteration 1\n",
      "D: -0.08467310667037964\n",
      "GP: 0.09395705163478851\n",
      "Gradient norm: 1.0322911739349365\n",
      "G: -0.7525038719177246\n",
      "Distance: 0.08467310667037964\n",
      "\n",
      "Epoch 80\n",
      "Iteration 1\n",
      "D: -0.09715926647186279\n",
      "GP: 0.08169528096914291\n",
      "Gradient norm: 0.9981389045715332\n",
      "G: -0.7985560894012451\n",
      "Distance: 0.09715926647186279\n",
      "\n",
      "Epoch 81\n",
      "Iteration 1\n",
      "D: -0.06399637460708618\n",
      "GP: 0.06551368534564972\n",
      "Gradient norm: 0.9907750487327576\n",
      "G: -0.8458228707313538\n",
      "Distance: 0.06399637460708618\n",
      "\n",
      "Epoch 82\n",
      "Iteration 1\n",
      "D: -0.029998183250427246\n",
      "GP: 0.03293874114751816\n",
      "Gradient norm: 0.998272716999054\n",
      "G: -0.9543008208274841\n",
      "Distance: 0.029998183250427246\n",
      "\n",
      "Epoch 83\n",
      "Iteration 1\n",
      "D: 0.010068416595458984\n",
      "GP: 0.027976296842098236\n",
      "Gradient norm: 1.0116777420043945\n",
      "G: -1.0275026559829712\n",
      "Distance: -0.010068416595458984\n",
      "\n",
      "Epoch 84\n",
      "Iteration 1\n",
      "D: -0.005566239356994629\n",
      "GP: 0.030935222283005714\n",
      "Gradient norm: 0.9917154908180237\n",
      "G: -1.0708119869232178\n",
      "Distance: 0.005566239356994629\n",
      "\n",
      "Epoch 85\n",
      "Iteration 1\n",
      "D: 0.05600142478942871\n",
      "GP: 0.02568880468606949\n",
      "Gradient norm: 0.9957517981529236\n",
      "G: -1.1477572917938232\n",
      "Distance: -0.05600142478942871\n",
      "\n",
      "Epoch 86\n",
      "Iteration 1\n",
      "D: 0.07503032684326172\n",
      "GP: 0.0329313762485981\n",
      "Gradient norm: 0.9853378534317017\n",
      "G: -1.1733297109603882\n",
      "Distance: -0.07503032684326172\n",
      "\n",
      "Epoch 87\n",
      "Iteration 1\n",
      "D: 0.12346279621124268\n",
      "GP: 0.01979399472475052\n",
      "Gradient norm: 0.993140459060669\n",
      "G: -1.2479957342147827\n",
      "Distance: -0.12346279621124268\n",
      "\n",
      "Epoch 88\n",
      "Iteration 1\n",
      "D: 0.09539735317230225\n",
      "GP: 0.021672740578651428\n",
      "Gradient norm: 0.9958810806274414\n",
      "G: -1.2680922746658325\n",
      "Distance: -0.09539735317230225\n",
      "\n",
      "Epoch 89\n",
      "Iteration 1\n",
      "D: 0.15388357639312744\n",
      "GP: 0.025700515136122704\n",
      "Gradient norm: 0.9856438636779785\n",
      "G: -1.3244683742523193\n",
      "Distance: -0.15388357639312744\n",
      "\n",
      "Epoch 90\n",
      "Iteration 1\n",
      "D: 0.13890480995178223\n",
      "GP: 0.012764070183038712\n",
      "Gradient norm: 0.9993640780448914\n",
      "G: -1.3698945045471191\n",
      "Distance: -0.13890480995178223\n",
      "\n",
      "Epoch 91\n",
      "Iteration 1\n",
      "D: 0.1631253957748413\n",
      "GP: 0.027383163571357727\n",
      "Gradient norm: 0.980594277381897\n",
      "G: -1.386482834815979\n",
      "Distance: -0.1631253957748413\n",
      "\n",
      "Epoch 92\n",
      "Iteration 1\n",
      "D: 0.18512248992919922\n",
      "GP: 0.03368852660059929\n",
      "Gradient norm: 0.986840546131134\n",
      "G: -1.3965866565704346\n",
      "Distance: -0.18512248992919922\n",
      "\n",
      "Epoch 93\n",
      "Iteration 1\n",
      "D: 0.21252727508544922\n",
      "GP: 0.04135650023818016\n",
      "Gradient norm: 0.9730199575424194\n",
      "G: -1.3876659870147705\n",
      "Distance: -0.21252727508544922\n",
      "\n",
      "Epoch 94\n",
      "Iteration 1\n",
      "D: 0.24826288223266602\n",
      "GP: 0.01595122180879116\n",
      "Gradient norm: 0.9908859729766846\n",
      "G: -1.415541410446167\n",
      "Distance: -0.24826288223266602\n",
      "\n",
      "Epoch 95\n",
      "Iteration 1\n",
      "D: 0.24277198314666748\n",
      "GP: 0.04840872809290886\n",
      "Gradient norm: 0.9770819544792175\n",
      "G: -1.4530305862426758\n",
      "Distance: -0.24277198314666748\n",
      "\n",
      "Epoch 96\n",
      "Iteration 1\n",
      "D: 0.24873220920562744\n",
      "GP: 0.04063666611909866\n",
      "Gradient norm: 0.9770001769065857\n",
      "G: -1.454466462135315\n",
      "Distance: -0.24873220920562744\n",
      "\n",
      "Epoch 97\n",
      "Iteration 1\n",
      "D: 0.2694091796875\n",
      "GP: 0.05697345361113548\n",
      "Gradient norm: 0.9791274070739746\n",
      "G: -1.4567698240280151\n",
      "Distance: -0.2694091796875\n",
      "\n",
      "Epoch 98\n",
      "Iteration 1\n",
      "D: 0.24910545349121094\n",
      "GP: 0.047009602189064026\n",
      "Gradient norm: 0.9888406991958618\n",
      "G: -1.4830292463302612\n",
      "Distance: -0.24910545349121094\n",
      "\n",
      "Epoch 99\n",
      "Iteration 1\n",
      "D: 0.26479220390319824\n",
      "GP: 0.055320993065834045\n",
      "Gradient norm: 0.9818992614746094\n",
      "G: -1.4865984916687012\n",
      "Distance: -0.26479220390319824\n",
      "\n",
      "Epoch 100\n",
      "Iteration 1\n",
      "D: 0.2641730308532715\n",
      "GP: 0.04829084500670433\n",
      "Gradient norm: 0.9680651426315308\n",
      "G: -1.5115498304367065\n",
      "Distance: -0.2641730308532715\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 100\n",
    "trainer.train(data_loader, epochs,  save_training_gif=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator(generator.sample_latent(num_samples= 1000)).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = [(x,y) for x in range(no_vars) for y in range(no_vars) if y>x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=no_vars, ncols=no_vars, sharex=True, sharey=True, squeeze=True,figsize=(10,10))\n",
    "for y in axes:\n",
    "    for x in y:\n",
    "        x.set_xticklabels([])\n",
    "        x.set_yticklabels([])\n",
    "\n",
    "for i,j in combinations:\n",
    "    sns.kdeplot(X_majority[:,i], X_majority[:,j], alpha=0.5, cmap=\"Blues\", ax=axes[(j,i)])\n",
    "    sns.kdeplot(X_minority[:,i], X_minority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(j,i)])\n",
    "fig.savefig(f'../img/cont_sample_tr_iter_{trainer.G.training_iterations}.png',format='png', dpi=100)\n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 90\n",
    "\n",
    "for _ in range(30):\n",
    "    trainer.train(data_loader, epochs)\n",
    "    \n",
    "    \n",
    "    if modus == 'full':\n",
    "        fake_minority = generator(*generator.sample_latent(num_samples= 1000, class_index=1)).data.numpy()\n",
    "        fake_majority = generator(*generator.sample_latent(num_samples= 1000, class_index=0)).data.numpy()\n",
    "    elif modus == 'minority':\n",
    "        fake_minority = generator(generator.sample_latent(num_samples= 1000)).data.numpy()\n",
    "        \n",
    "    fig, axes = plt.subplots(nrows=no_vars, ncols=no_vars, sharex=True, squeeze=True,figsize=(10,10))\n",
    "    for y in axes:\n",
    "        for x in y:\n",
    "            x.set_xticklabels([])\n",
    "            x.set_yticklabels([])\n",
    "    \n",
    "    for i in range(no_vars):\n",
    "        sns.kdeplot(X_minority[:,i], alpha=0.5, shade=True, color=\"blue\", ax=axes[(i,i)])\n",
    "        sns.kdeplot(fake_minority[:,i], alpha=0.5, shade=True, color=\"green\", ax=axes[(i,i)])\n",
    "    \n",
    "    for i,j in combinations:\n",
    "        axes[(i,j)].set_ylim(0,1)\n",
    "        # majority (upper right)\n",
    "        if modus == 'full':\n",
    "            sns.kdeplot(X_majority[0:1000,i], X_majority[0:1000,j], alpha=0.5, cmap=\"Blues\", ax=axes[(i,j)])\n",
    "            sns.kdeplot(fake_majority[:,i], fake_majority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(i,j)], )\n",
    "        \n",
    "        # minority (lower left)\n",
    "        sns.kdeplot(X_minority[:,i], X_minority[:,j], alpha=0.5, cmap=\"Blues\", ax=axes[(j,i)])\n",
    "        sns.kdeplot(fake_minority[:,i], fake_minority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(j,i)])\n",
    "        \n",
    "    fig.savefig(f'../img/cont_sample_tr_iter_{trainer.G.training_iterations}.png',format='png', dpi=200)\n",
    "        #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = f\"multinormal_n{N//1000}_k{no_vars}_{modus}\"\n",
    "torch.save(generator.state_dict(), f\"../models/wgan_generator_{desc}_{generator.training_iterations}\")\n",
    "torch.save(discriminator.state_dict(), f\"../models/wgan_discriminator_{desc}_{generator.training_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"multinormal_n10_k4_c2_6999\"\n",
    "generator.load_state_dict(torch.load(f\"../models/wgan_generator_{file_name}\"))\n",
    "discriminator.load_state_dict(torch.load(f\"../models/wgan_discriminator_{file_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_minority = generator(*generator.sample_latent(num_samples= minority_samples, class_index=1)).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_minority, axis=0))\n",
    "print(np.mean(fake_minority, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(X_minority, q=np.arange(0,1,0.1), axis=0))\n",
    "print(np.quantile(fake_minority, q=np.arange(0,1,0.1), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.cov(X_minority, rowvar=False) - np.cov(fake_minority,rowvar=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = X_minority.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = generator(*generator.sample_latent(num_samples= sample_size, class_index=1)).data.numpy()\n",
    "#fake = generator(generator.sample_latent(num_samples= sample_size)).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fakereal = np.vstack([X_minority, \n",
    "                        fake])\n",
    "y_fakereal = np.concatenate([np.zeros(X_minority.shape[0]), \n",
    "                        np.ones(fake.shape[0])]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, min_samples_leaf=20, n_jobs=10)\n",
    "model_fakereal = clf.fit(X_fakereal, y_fakereal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fakereal = model_fakereal.predict_proba(X_fakereal)[:,1]\n",
    "roc_auc_score(y_fakereal, pred_fakereal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive performance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = np.argmax(y_train, axis=1)\n",
    "y_test_bin = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_auc(model_library, X, y_true):\n",
    "    auc = {}\n",
    "    for model in model_library.keys():\n",
    "        pred = model_library[model].predict_proba(X_test)[:,1]\n",
    "        auc[model] = roc_auc_score(y_true, pred)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_samples = X_minority.shape[0]\n",
    "majority_samples = X_majority.shape[0]\n",
    "\n",
    "fake_minority = generator(*generator.sample_latent(num_samples= minority_samples, class_index=1)).data.numpy()\n",
    "fake_majority = generator(*generator.sample_latent(num_samples= majority_samples, class_index=0)).data.numpy()\n",
    "\n",
    "X_synthetic = np.vstack([fake_majority, \n",
    "                         fake_minority])\n",
    "y_synthetic = np.concatenate([np.zeros(majority_samples), \n",
    "                              np.ones(minority_samples)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_org = DecisionTreeClassifier(max_depth=10) #LogisticRegression(solver='saga') \n",
    "clf_fake = DecisionTreeClassifier(max_depth=10) #LogisticRegression(solver='saga')\n",
    "\n",
    "predictive = {}\n",
    "predictive[\"real\"] = clf_org.fit(X=X_train, y=y_train_bin)\n",
    "predictive[\"synthetic\"] = clf_fake.fit(X=X_synthetic, y=y_synthetic)\n",
    "\n",
    "test_auc(predictive, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\"original\":[],\"GANbalanced\":[]}\n",
    "for i in range(200):\n",
    "    sample_size = X_minority.shape[0]*4\n",
    "    X_fake = generator(*generator.sample_latent(num_samples= sample_size, class_index=1)).data.numpy()\n",
    "    #X_fake = generator(generator.sample_latent(num_samples= sample_size, class_index=None)).data.numpy()\n",
    "    y_fake = np.ones(shape=[sample_size])\n",
    "\n",
    "    X_up = np.vstack([X_train,X_fake])\n",
    "    y_up = np.hstack([y_train_bin,y_fake])\n",
    "\n",
    "    clf_org = DecisionTreeClassifier(max_depth=5)\n",
    "    clf_fake = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "    upsampling = {}\n",
    "    upsampling[\"original\"] =  clf_org.fit(X=X_train, y=y_train_bin)\n",
    "    upsampling[\"GANbalanced\"] = clf_fake.fit(X=X_up, y=y_up)\n",
    "    \n",
    "    performance_temp = test_auc(upsampling, X_test, y_test_bin)\n",
    "    for model in performance_temp:\n",
    "        performance[model].append(performance_temp[model])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(performance).mean())\n",
    "print(pd.DataFrame(performance).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_function(X, y, clf, ax):\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.8, c=y, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "plot_decision_function(X_train, y_train, upsampling[\"original\"], ax1)\n",
    "plot_decision_function(X_up, y_up, upsampling[\"GANbalanced\"], ax2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of dimensionality on SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With increasing dimensionality, we expect SMOTE's underlying nearest neighbor approach to fail to capture relevant neighborhoods. We measure SMOTE performance in terms of RF being able to differentiate between real and synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC, SMOTE\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = {}\n",
    "\n",
    "n_features = 320\n",
    "# Create single dataset to avoid random effects\n",
    "# Only works for all informative features\n",
    "X_full,y = make_classification(n_samples=10000, weights=[0.9,0.1], n_clusters_per_class=1,\n",
    "                              n_features=n_features, \n",
    "                              n_informative=n_features, \n",
    "                              n_redundant=0, n_repeated=0,\n",
    "                             random_state=123)\n",
    "\n",
    "# Drop variables until desired dimensionality\n",
    "for k in [5,10,20,40,80,160,320]: #\n",
    "    X = X_full[:,0:k]\n",
    "    \n",
    "    # Sample synthetic SMOTE data\n",
    "    smote = SMOTE(sampling_strategy = {1:np.sum(y)*2}, k_neighbors=50,\n",
    "                  random_state=123, n_jobs=20)\n",
    "    X_smote, y_smote = smote.fit_sample(X,y)\n",
    "    \n",
    "    # Create fake/real discrimination problem\n",
    "    X_fakereal = np.vstack([X[y==1], X_smote])\n",
    "    y_fakereal = np.concatenate([np.zeros(X[y==1].shape[0]), \n",
    "                                 np.ones(  X_smote.shape[0])]).flatten()\n",
    "    \n",
    "    X_fakereal_train, X_fakereal_test, y_fakereal_train, y_fakereal_test =\\\n",
    "        train_test_split(X_fakereal, y_fakereal, test_size=0.5)\n",
    "    clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=50, n_jobs=20)\n",
    "    model_fakereal = clf.fit(X_fakereal_train, y_fakereal_train)\n",
    "\n",
    "    pred_fakereal = model_fakereal.predict_proba(X_fakereal_test)[:,1]\n",
    "    auc[k] = roc_auc_score(y_fakereal_test, pred_fakereal)\n",
    "    \n",
    "print(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(auc.keys(), auc.values())\n",
    "plt.xlabel(\"No. of variables (10,000 minority observations )\")\n",
    "plt.ylabel(\"Discriminator AUC (SMOTE)\")\n",
    "plt.savefig(\"../img/SMOTE_performance_over_variables_10k_minority.png\", format='png',dpi=200)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
