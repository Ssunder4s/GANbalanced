{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n",
      "env: NUMEXPR_NUM_THREADS=1\n",
      "env: OMP_NUM_THREADS=1\n",
      "env: OPENBLAS_NUM_THREADS=1\n",
      "env: VECLIB_MAXIMUM_THREADS=1\n"
     ]
    }
   ],
   "source": [
    "%env MKL_NUM_THREADS=1\n",
    "%env NUMEXPR_NUM_THREADS=1\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env OPENBLAS_NUM_THREADS=1\n",
    "%env VECLIB_MAXIMUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/RDC/hauptjoh.hub/utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from lift.perc_lift_score import perc_lift_score\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Samplers\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC\n",
    "from wgan.imblearn import GANbalancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "# X,y = make_classification(n_samples=4000, n_features=20, weights=[0.99,0.01], \n",
    "#                           n_informative=20, n_redundant=0, n_clusters_per_class=5)\n",
    "\n",
    "# X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "path = \"/home/RDC/hauptjoh.hub/data\"\n",
    "#X,y = data_loader.load_coil00(path)\n",
    "X,y = data_loader.load_dmc10(path)\n",
    "\n",
    "#y = np.eye(y.nunique())[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize index lists\n",
    "idx_cont = None\n",
    "idx_cat  = None\n",
    "\n",
    "if idx_cat is None:\n",
    "    idx_cat = list(np.where(X.dtypes=='category')[0])\n",
    "    idx_cat = [int(x) for x in idx_cat]\n",
    "\n",
    "if idx_cont is None:\n",
    "    idx_cont = [x for x in range(X.shape[1]) if x not in idx_cat]\n",
    "    idx_cont = [int(x) for x in idx_cont]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding tuples\n",
    "categorical = None\n",
    "if idx_cat is not None:\n",
    "    categorical = [(i,\n",
    "                    len(X.iloc[:,i].cat.categories),\n",
    "                    int(min(15., np.ceil(0.5*len(X.iloc[:,i].cat.categories))))\n",
    "                   )\n",
    "                    for i in idx_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure categorical variables are encoded from 0\n",
    "if np.any([idx>min(idx_cat) for idx in idx_cont]):\n",
    "    raise ValueError(\"Variables need to be ordered [cont, cat]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.to_numpy(dtype=np.float32)\n",
    "y=y.to_numpy(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from experiment.experiment_config import experiment_config\n",
    "#scorers, models, samplers = experiment_config(X, idx_cont=None, idx_cat=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Samplers\n",
    "scorers = {'auc':make_scorer(roc_auc_score, needs_proba=True),\n",
    "          'TDLift':make_scorer(perc_lift_score, needs_proba=True, percentile=0.1)}\n",
    "\n",
    "### Models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear'), {\n",
    "    \"C\": [10]\n",
    "}))\n",
    "# models.append(('RF', RandomForestClassifier(), {\n",
    "#     \"n_estimators\":[200],\n",
    "#     \"max_features\":[\"sqrt\"],\n",
    "#     \"min_samples_leaf\":[20]\n",
    "# }))\n",
    "\n",
    "### Samplers\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from wgan.imblearn import GANbalancer\n",
    "\n",
    "samplers = []\n",
    "\n",
    "# GAN\n",
    "\n",
    "samplers.append(('cGAN', GANbalancer(\n",
    "        idx_cont=idx_cont, categorical=categorical, batch_size = 128, auxiliary=True\n",
    "), {\n",
    "    'generator_input'  : [40,100],\n",
    "    'generator_layers' : [[40,40],[100,100]],\n",
    "    'critic_layers'    : [[40],[100]],\n",
    "    'n_iter'           : [100000],\n",
    "    'critic_iterations': [2]\n",
    "}))\n",
    "\n",
    "# baseline\n",
    "samplers.append(('unbalanced', None, {}))\n",
    "\n",
    "SMOTE\n",
    "samplers.append(('SMOTE', SMOTENC(categorical_features=idx_cat), {\n",
    "    'k_neighbors':[5,10,15,20,25]\n",
    "}))\n",
    "\n",
    "# # ADASYN\n",
    "# samplers.append(('ADASYN', ADASYN(), {\n",
    "#     'n_neighbors':[5,10]\n",
    "# }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_sampler = ColumnTransformer([\n",
    "    ('scaler', MinMaxScaler(), idx_cont),\n",
    "    ('pass',   'passthrough',  idx_cat)\n",
    "])\n",
    "\n",
    "preproc_clf = ColumnTransformer([\n",
    "    ('pass', 'passthrough', idx_cont),\n",
    "    ('ohe',   OneHotEncoder(categories='auto', handle_unknown='ignore'),  idx_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  40 out of  40 | elapsed: 391.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  40 out of  40 | elapsed: 384.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  40 out of  40 | elapsed: 388.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  40 out of  40 | elapsed: 381.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  40 out of  40 | elapsed: 394.5min finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 2465.8min finished\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [41:05:46<00:00, 147946.38s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 1/3 [41:05:46<82:11:32, 147946.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:   17.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   45.2s finished\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:45<00:00, 45.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 2/3 [41:06:31<28:46:16, 103576.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  20 out of  25 | elapsed:   14.3s remaining:    3.6s\n",
      "[Parallel(n_jobs=16)]: Done  25 out of  25 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  20 out of  25 | elapsed:   12.1s remaining:    3.0s\n",
      "[Parallel(n_jobs=16)]: Done  25 out of  25 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  20 out of  25 | elapsed:   13.4s remaining:    3.4s\n",
      "[Parallel(n_jobs=16)]: Done  25 out of  25 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  20 out of  25 | elapsed:   13.4s remaining:    3.3s\n",
      "[Parallel(n_jobs=16)]: Done  25 out of  25 | elapsed:   13.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  20 out of  25 | elapsed:   12.2s remaining:    3.1s\n",
      "[Parallel(n_jobs=16)]: Done  25 out of  25 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.3min finished\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [01:20<00:00, 80.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 3/3 [41:07:52<00:00, 72527.44s/it]    \u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "\n",
    "score_outer = {}\n",
    "\n",
    "for sampler_name, sampler, sampler_grid in tqdm(samplers):\n",
    "    \n",
    "    sampler_grid = {'sampler__'+key:item for key, item in sampler_grid.items()}\n",
    "    \n",
    "    score_inner = {}\n",
    "\n",
    "    for model_name, model, model_grid in tqdm(models):\n",
    "\n",
    "        pipeline = Pipeline(memory='./.cachedir', steps=[\n",
    "            ('preproc_sampler', preproc_sampler),\n",
    "            ('sampler', sampler),\n",
    "            ('preproc_clf', preproc_clf),\n",
    "            ('classifier', model)\n",
    "          ])\n",
    "        \n",
    "        model_grid = {'classifier__'+key:item for key, item in model_grid.items()}\n",
    "        p_grid = {**sampler_grid, **model_grid}\n",
    "        \n",
    "        inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "            \n",
    "        clf = GridSearchCV(pipeline, param_grid= p_grid, cv=inner_cv, scoring=scorers, refit='auc', \n",
    "                           return_train_score=True, iid=False, \n",
    "                           n_jobs=16, pre_dispatch=32, verbose=1)\n",
    "\n",
    "        score_inner[model_name] = cross_validate(clf, X=X,y=y,cv=outer_cv , scoring=scorers, return_train_score=True,\n",
    "                                    return_estimator=True, verbose=1, error_score='raise')\n",
    "    score_outer[sampler_name] = score_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_outer['SMOTE'][\"LR\"][\"estimator\"][1].best_estimator_.named_steps[\"sampler\"].sampling_strategy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        auc    auc_sd   lift0.1  lift0.1_sd model     sampler\n",
      "0  0.598723  0.016157  1.044356    0.008771    LR        cGAN\n",
      "1  0.623048  0.005692  1.058126    0.004475    LR  unbalanced\n",
      "2  0.573626  0.005416  1.034074    0.006696    LR       SMOTE\n"
     ]
    }
   ],
   "source": [
    "scores = pd.DataFrame([{\n",
    "  'sampler':sampler_name, 'model':model_name, \n",
    "    'auc':np.mean(model[\"test_auc\"]),  'auc_sd':np.std(model[\"test_auc\"]),\n",
    "    'lift0.1':np.mean(model[\"test_TDLift\"]),  'lift0.1_sd':np.std(model[\"test_TDLift\"]),\n",
    "} for sampler_name, sampler in score_outer.items()\n",
    "    for model_name, model in sampler.items()]\n",
    ")\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = {sampler_name:\n",
    "    {model_name:\n",
    "    # vstack result DataFrame for each outer fold\n",
    "        pd.concat([ \n",
    "            # Inner CV tuning results as DataFrame\n",
    "            pd.concat([pd.DataFrame(inner_cv.cv_results_['params']).astype(str), \n",
    "                       pd.DataFrame({\n",
    "                           'mean_test_auc':inner_cv.cv_results_['mean_test_auc'],\n",
    "                           'std_test_auc':inner_cv.cv_results_['std_test_auc'],\n",
    "                           'mean_test_TDLift':inner_cv.cv_results_['mean_test_TDLift'],\n",
    "                           'std_test_TDLift':inner_cv.cv_results_['std_test_TDLift']\n",
    "                       })\n",
    "                      ], sort=False, ignore_index=False, axis=1)\n",
    "            for inner_cv in model['estimator']]).groupby(list(model['estimator'][0].cv_results_['params'][0].keys())).mean().reset_index()\n",
    "            for model_name, model in sampler.items()}\n",
    "          for sampler_name, sampler in score_outer.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier__C</th>\n",
       "      <th>sampler__critic_iterations</th>\n",
       "      <th>sampler__critic_layers</th>\n",
       "      <th>sampler__generator_input</th>\n",
       "      <th>sampler__generator_layers</th>\n",
       "      <th>sampler__n_iter</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>mean_test_TDLift</th>\n",
       "      <th>std_test_TDLift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[100]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.572371</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>1.036865</td>\n",
       "      <td>0.011340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[100]</td>\n",
       "      <td>100</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>0.018025</td>\n",
       "      <td>1.032092</td>\n",
       "      <td>0.010060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[100]</td>\n",
       "      <td>40</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.570560</td>\n",
       "      <td>0.013995</td>\n",
       "      <td>1.036269</td>\n",
       "      <td>0.009695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[100]</td>\n",
       "      <td>40</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.017895</td>\n",
       "      <td>1.029476</td>\n",
       "      <td>0.011564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[40]</td>\n",
       "      <td>100</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.586622</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>1.041685</td>\n",
       "      <td>0.010522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[40]</td>\n",
       "      <td>100</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.592664</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>1.041733</td>\n",
       "      <td>0.009956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[40]</td>\n",
       "      <td>40</td>\n",
       "      <td>[100, 100]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.576302</td>\n",
       "      <td>0.014907</td>\n",
       "      <td>1.038106</td>\n",
       "      <td>0.009637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[40]</td>\n",
       "      <td>40</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.586792</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>1.041869</td>\n",
       "      <td>0.009653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier__C sampler__critic_iterations sampler__critic_layers  \\\n",
       "0            10                          2                  [100]   \n",
       "1            10                          2                  [100]   \n",
       "2            10                          2                  [100]   \n",
       "3            10                          2                  [100]   \n",
       "4            10                          2                   [40]   \n",
       "5            10                          2                   [40]   \n",
       "6            10                          2                   [40]   \n",
       "7            10                          2                   [40]   \n",
       "\n",
       "  sampler__generator_input sampler__generator_layers sampler__n_iter  \\\n",
       "0                      100                [100, 100]          100000   \n",
       "1                      100                  [40, 40]          100000   \n",
       "2                       40                [100, 100]          100000   \n",
       "3                       40                  [40, 40]          100000   \n",
       "4                      100                [100, 100]          100000   \n",
       "5                      100                  [40, 40]          100000   \n",
       "6                       40                [100, 100]          100000   \n",
       "7                       40                  [40, 40]          100000   \n",
       "\n",
       "   mean_test_auc  std_test_auc  mean_test_TDLift  std_test_TDLift  \n",
       "0       0.572371      0.020110          1.036865         0.011340  \n",
       "1       0.568733      0.018025          1.032092         0.010060  \n",
       "2       0.570560      0.013995          1.036269         0.009695  \n",
       "3       0.559006      0.017895          1.029476         0.011564  \n",
       "4       0.586622      0.016635          1.041685         0.010522  \n",
       "5       0.592664      0.012136          1.041733         0.009956  \n",
       "6       0.576302      0.014907          1.038106         0.009637  \n",
       "7       0.586792      0.015623          1.041869         0.009653  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_results[\"cGAN\"][\"LR\"].sort_values([\"sampler__n_iter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results[\"cGAN\"][\"LR\"].sort_values([\"sampler__n_iter\"]).to_csv(\"tuning_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_scores =  pd.DataFrame([{\n",
    "  'sampler':sampler_name, 'model':model_name,\n",
    "    'parameter':param_name,\n",
    "    'parameter_value':str(param_value),\n",
    "    'auc':cv.cv_results_['mean_test_auc'][i],  'auc_sd':cv.cv_results_[\"std_test_auc\"][i],\n",
    "    'lift0.1':cv.cv_results_[\"mean_test_TDLift\"][i],  'lift0.1_sd':cv.cv_results_[\"std_test_TDLift\"][i]\n",
    "}   for sampler_name, sampler in score_outer.items()\n",
    "    for model_name, model in sampler.items()\n",
    "    for cv in model['estimator']\n",
    "    for i, (param_name, param_value) in enumerate(cv.cv_results_['params'][0].items())\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_scores.groupby(['sampler','model','parameter','parameter_value']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only sampler test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
